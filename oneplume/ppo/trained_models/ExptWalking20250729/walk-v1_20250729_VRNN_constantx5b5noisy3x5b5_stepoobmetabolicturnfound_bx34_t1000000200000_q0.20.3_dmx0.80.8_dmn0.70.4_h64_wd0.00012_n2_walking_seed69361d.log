CUDA: False
Namespace(algo='ppo', lr=0.0003, eps=1e-05, alpha=0.99, gamma=0.99, use_gae=True, gae_lambda=0.95, entropy_coef=0.005, value_loss_coef=0.5, max_grad_norm=0.5, seed=6936, cuda_deterministic=False, num_processes=2, num_steps=2048, ppo_epoch=10, num_mini_batch=2, clip_param=0.2, log_interval=1, save_interval=100, no_cuda=False, use_proper_time_limits=False, recurrent_policy=True, use_linear_lr_decay=True, env_name='plume', log_dir='/tmp/gym/', save_dir='./trained_models/ExptWalking20250729/', dynamic=False, eval_type='fixed', eval_episodes=20, eval_interval=None, weight_decay=0.00012, rnn_type='VRNN', hidden_size=64, betadist=False, stacking=0, masking=None, stride=1, dataset=['constantx5b5', 'noisy3x5b5'], num_env_steps=[1000000, 200000], qvar=[0.2, 0.3], birthx=[3.0, 4.0], diff_max=[0.8, 0.8], diff_min=[0.7, 0.4], birthx_max=1.0, dryrun=False, curriculum=False, turnx=1.0, movex=1.0, auto_movex=False, auto_reward=False, loc_algo='uniform', time_algo='uniform', env_dt=0.04, outsuffix='walk-v1_20250729_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.20.3_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed69361d', walking=True, radiusx=1.0, diffusion_min=1.0, diffusion_max=1.0, r_shaping=['step', 'oob', 'metabolic', 'turn', 'found'], wind_rel=True, action_feedback=False, squash_action=True, flipping=True, odor_scaling=True, stray_max=2.0, test_episodes=50, viz_episodes=10, model_fname='', obs_noise=0.0, act_noise=0.0, cuda=False)
PPO Args ---> Namespace(algo='ppo', lr=0.0003, eps=1e-05, alpha=0.99, gamma=0.99, use_gae=True, gae_lambda=0.95, entropy_coef=0.005, value_loss_coef=0.5, max_grad_norm=0.5, seed=6936, cuda_deterministic=False, num_processes=2, num_steps=2048, ppo_epoch=10, num_mini_batch=2, clip_param=0.2, log_interval=1, save_interval=100, no_cuda=False, use_proper_time_limits=False, recurrent_policy=True, use_linear_lr_decay=True, env_name='plume', log_dir='/tmp/gym/', save_dir='./trained_models/ExptWalking20250729/', dynamic=False, eval_type='fixed', eval_episodes=20, eval_interval=None, weight_decay=0.00012, rnn_type='VRNN', hidden_size=64, betadist=False, stacking=0, masking=None, stride=1, dataset=['constantx5b5', 'noisy3x5b5'], num_env_steps=[1000000, 200000], qvar=[0.2, 0.3], birthx=[3.0, 4.0], diff_max=[0.8, 0.8], diff_min=[0.7, 0.4], birthx_max=1.0, dryrun=False, curriculum=False, turnx=1.0, movex=1.0, auto_movex=False, auto_reward=False, loc_algo='uniform', time_algo='uniform', env_dt=0.04, outsuffix='walk-v1_20250729_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.20.3_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed69361d', walking=True, radiusx=1.0, diffusion_min=1.0, diffusion_max=1.0, r_shaping=['step', 'oob', 'metabolic', 'turn', 'found'], wind_rel=True, action_feedback=False, squash_action=True, flipping=True, odor_scaling=True, stray_max=2.0, test_episodes=50, viz_episodes=10, model_fname='', obs_noise=0.0, act_noise=0.0, cuda=False)
Using Precomputed Plume...
Using Precomputed Plume...
2025-07-29 23:23:57.206 python[86721:52372645] +[NSXPCSharedListener endpointForReply:withListenerName:replyErrorCode:]: an error occurred while attempting to obtain endpoint for listener 'ClientCallsAuxiliary': Connection invalid
2025-07-29 23:23:57.206 python[86720:52372644] +[NSXPCSharedListener endpointForReply:withListenerName:replyErrorCode:]: an error occurred while attempting to obtain endpoint for listener 'ClientCallsAuxiliary': Connection invalid
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x17ba5ecd0>, 't_val_min': 10.0, 'sim_steps_max': 2000, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 3.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.2, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.7, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': True, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 6936, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
Using MLPBase
hidden_size 64
Using VanillaRNN
Saved ./trained_models/ExptWalking20250729//plume_walk-v1_20250729_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.20.3_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed69361d.pt.start
Stage: 0/2 - constantx5b5 b3.0 q0.2 n1000000
Saved ./trained_models/ExptWalking20250729/plume_walk-v1_20250729_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.20.3_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed69361d.pt
Update 0/244, T 4096, FPS 189, 27-training-episode: mean/median 30.9/-3.3, min/max -11.4/94.3
Update 1/244, T 8192, FPS 205, 46-training-episode: mean/median 40.8/-2.5, min/max -16.8/95.2
Update 2/244, T 12288, FPS 210, 50-training-episode: mean/median 44.6/86.6, min/max -16.8/97.0
Update 3/244, T 16384, FPS 207, 50-training-episode: mean/median 54.5/90.4, min/max -16.8/97.0
Update 4/244, T 20480, FPS 206, 50-training-episode: mean/median 55.6/90.4, min/max -12.2/97.7
Update 5/244, T 24576, FPS 202, 50-training-episode: mean/median 51.8/90.4, min/max -12.3/98.5
Update 6/244, T 28672, FPS 204, 50-training-episode: mean/median 43.5/44.4, min/max -18.9/98.5
Update 7/244, T 32768, FPS 204, 50-training-episode: mean/median 33.6/-2.9, min/max -18.9/97.1
Update 8/244, T 36864, FPS 202, 50-training-episode: mean/median 26.6/-2.9, min/max -15.2/97.7
Update 9/244, T 40960, FPS 203, 50-training-episode: mean/median 29.6/-3.1, min/max -15.2/97.7
Update 10/244, T 45056, FPS 201, 50-training-episode: mean/median 35.6/-2.4, min/max -12.0/98.2
Update 11/244, T 49152, FPS 200, 50-training-episode: mean/median 37.8/-2.7, min/max -12.0/97.5
Update 12/244, T 53248, FPS 200, 50-training-episode: mean/median 35.0/-3.0, min/max -16.3/97.5
Update 13/244, T 57344, FPS 199, 50-training-episode: mean/median 29.0/-4.2, min/max -16.3/97.3
Update 14/244, T 61440, FPS 200, 50-training-episode: mean/median 31.1/-3.9, min/max -15.6/97.6
Update 15/244, T 65536, FPS 200, 50-training-episode: mean/median 39.3/-2.9, min/max -13.1/97.6
Update 16/244, T 69632, FPS 200, 50-training-episode: mean/median 32.2/-3.1, min/max -13.9/98.9
Update 17/244, T 73728, FPS 201, 50-training-episode: mean/median 30.5/-3.2, min/max -13.9/98.9
Update 18/244, T 77824, FPS 202, 50-training-episode: mean/median 30.4/-3.4, min/max -11.2/98.2
Update 19/244, T 81920, FPS 202, 50-training-episode: mean/median 30.1/-3.7, min/max -13.3/98.7
Update 20/244, T 86016, FPS 202, 50-training-episode: mean/median 30.0/-4.9, min/max -13.3/98.7
Update 21/244, T 90112, FPS 203, 50-training-episode: mean/median 26.3/-4.9, min/max -11.1/97.7
Update 22/244, T 94208, FPS 203, 50-training-episode: mean/median 26.3/-4.0, min/max -13.9/97.9
Update 23/244, T 98304, FPS 203, 50-training-episode: mean/median 24.6/-3.7, min/max -13.9/98.4
Update 24/244, T 102400, FPS 204, 50-training-episode: mean/median 30.5/-3.8, min/max -14.1/98.8
Update 25/244, T 106496, FPS 204, 50-training-episode: mean/median 27.9/-5.3, min/max -14.1/98.6
Update 26/244, T 110592, FPS 205, 50-training-episode: mean/median 34.6/-3.2, min/max -12.2/98.6
Update 27/244, T 114688, FPS 205, 50-training-episode: mean/median 40.9/-2.8, min/max -12.1/105.4
Update 28/244, T 118784, FPS 206, 50-training-episode: mean/median 36.4/-4.1, min/max -12.1/105.4
Update 29/244, T 122880, FPS 207, 50-training-episode: mean/median 40.3/-3.0, min/max -14.3/98.1
Update 30/244, T 126976, FPS 207, 50-training-episode: mean/median 40.4/-3.0, min/max -14.3/98.5
Update 31/244, T 131072, FPS 208, 50-training-episode: mean/median 30.1/-4.2, min/max -11.4/98.5
Update 32/244, T 135168, FPS 208, 50-training-episode: mean/median 22.5/-4.2, min/max -11.4/97.7
Update 33/244, T 139264, FPS 208, 50-training-episode: mean/median 26.8/-4.3, min/max -9.5/98.1
Update 34/244, T 143360, FPS 209, 50-training-episode: mean/median 34.6/-3.9, min/max -11.2/98.1
Update 35/244, T 147456, FPS 209, 50-training-episode: mean/median 37.1/-2.9, min/max -11.9/98.9
Update 36/244, T 151552, FPS 209, 50-training-episode: mean/median 29.1/-4.4, min/max -11.9/106.3
Update 37/244, T 155648, FPS 209, 50-training-episode: mean/median 37.3/-3.9, min/max -9.6/106.3
Update 38/244, T 159744, FPS 209, 50-training-episode: mean/median 37.1/-3.4, min/max -10.6/98.3
Update 39/244, T 163840, FPS 209, 50-training-episode: mean/median 33.2/-3.2, min/max -11.2/98.6
Update 40/244, T 167936, FPS 210, 50-training-episode: mean/median 30.8/-3.7, min/max -9.6/98.5
Update 41/244, T 172032, FPS 210, 50-training-episode: mean/median 31.1/-4.2, min/max -9.2/99.3
Update 42/244, T 176128, FPS 210, 50-training-episode: mean/median 35.3/-4.0, min/max -9.3/106.1
Update 43/244, T 180224, FPS 210, 50-training-episode: mean/median 42.8/-2.8, min/max -10.1/106.3
Update 44/244, T 184320, FPS 210, 50-training-episode: mean/median 36.7/-3.6, min/max -10.2/98.9
Update 45/244, T 188416, FPS 210, 50-training-episode: mean/median 29.0/-4.1, min/max -9.6/98.7
Update 46/244, T 192512, FPS 211, 50-training-episode: mean/median 24.9/-4.6, min/max -10.0/98.4
Update 47/244, T 196608, FPS 211, 50-training-episode: mean/median 28.6/-4.7, min/max -10.7/99.0
Update 48/244, T 200704, FPS 211, 50-training-episode: mean/median 32.9/-4.5, min/max -9.5/99.4
Update 49/244, T 204800, FPS 211, 50-training-episode: mean/median 42.8/-2.3, min/max -10.2/98.8
Update 50/244, T 208896, FPS 211, 50-training-episode: mean/median 28.9/-3.4, min/max -10.2/98.6
Update 51/244, T 212992, FPS 211, 50-training-episode: mean/median 18.9/-5.1, min/max -11.0/98.6
Update 52/244, T 217088, FPS 211, 50-training-episode: mean/median 14.5/-5.7, min/max -11.0/98.6
Update 53/244, T 221184, FPS 211, 50-training-episode: mean/median 22.4/-4.9, min/max -11.1/98.6
Update 54/244, T 225280, FPS 211, 50-training-episode: mean/median 24.7/-4.5, min/max -12.1/99.2
Update 55/244, T 229376, FPS 211, 50-training-episode: mean/median 37.3/-3.2, min/max -9.6/99.2
Update 56/244, T 233472, FPS 211, 50-training-episode: mean/median 41.2/-3.4, min/max -9.6/98.9
Update 57/244, T 237568, FPS 212, 50-training-episode: mean/median 38.7/-4.8, min/max -9.4/98.9
Update 58/244, T 241664, FPS 212, 50-training-episode: mean/median 34.6/-4.8, min/max -9.6/98.2
Update 59/244, T 245760, FPS 212, 50-training-episode: mean/median 28.7/-5.1, min/max -9.1/98.1
Update 60/244, T 249856, FPS 212, 50-training-episode: mean/median 31.2/-4.7, min/max -9.4/107.7
Update 61/244, T 253952, FPS 212, 50-training-episode: mean/median 27.3/-3.4, min/max -10.3/107.7
Update 62/244, T 258048, FPS 212, 50-training-episode: mean/median 31.5/-3.6, min/max -8.7/99.2
Update 63/244, T 262144, FPS 212, 50-training-episode: mean/median 31.6/-3.4, min/max -9.2/99.2
Update 64/244, T 266240, FPS 212, 50-training-episode: mean/median 27.4/-3.4, min/max -9.3/99.0
Update 65/244, T 270336, FPS 212, 50-training-episode: mean/median 19.0/-4.2, min/max -10.8/99.5
Update 66/244, T 274432, FPS 212, 50-training-episode: mean/median 22.7/-5.2, min/max -10.8/99.5
Update 67/244, T 278528, FPS 212, 50-training-episode: mean/median 49.6/94.2, min/max -8.9/99.2
Update 68/244, T 282624, FPS 212, 50-training-episode: mean/median 39.8/-2.9, min/max -8.0/99.2
Update 69/244, T 286720, FPS 212, 50-training-episode: mean/median 41.7/-2.2, min/max -8.2/99.0
Update 70/244, T 290816, FPS 212, 50-training-episode: mean/median 37.7/-2.1, min/max -10.3/99.4
Update 71/244, T 294912, FPS 212, 50-training-episode: mean/median 45.4/45.2, min/max -8.5/99.4
Update 72/244, T 299008, FPS 213, 50-training-episode: mean/median 47.1/93.4, min/max -9.7/99.3
Update 73/244, T 303104, FPS 213, 50-training-episode: mean/median 49.5/94.7, min/max -9.8/99.3
Update 74/244, T 307200, FPS 213, 50-training-episode: mean/median 51.6/94.5, min/max -9.8/99.3
Update 75/244, T 311296, FPS 213, 50-training-episode: mean/median 50.0/94.6, min/max -9.6/107.0
Update 76/244, T 315392, FPS 213, 50-training-episode: mean/median 31.3/-3.8, min/max -9.1/99.1
Update 77/244, T 319488, FPS 213, 50-training-episode: mean/median 39.3/-2.4, min/max -10.9/97.7
Update 78/244, T 323584, FPS 213, 50-training-episode: mean/median 39.1/-2.5, min/max -10.9/99.0
Update 79/244, T 327680, FPS 213, 50-training-episode: mean/median 30.7/-4.6, min/max -9.4/99.4
Update 80/244, T 331776, FPS 213, 50-training-episode: mean/median 41.3/-2.4, min/max -10.2/99.0
Update 81/244, T 335872, FPS 213, 50-training-episode: mean/median 34.9/-4.1, min/max -10.1/98.7
Update 82/244, T 339968, FPS 213, 50-training-episode: mean/median 38.6/-2.9, min/max -10.1/98.1
Update 83/244, T 344064, FPS 213, 50-training-episode: mean/median 31.7/-3.6, min/max -9.0/107.9
Update 84/244, T 348160, FPS 213, 50-training-episode: mean/median 44.2/-2.4, min/max -10.2/108.8
Update 85/244, T 352256, FPS 213, 50-training-episode: mean/median 43.7/-2.8, min/max -10.2/108.8
Update 86/244, T 356352, FPS 213, 50-training-episode: mean/median 43.2/-2.8, min/max -9.0/98.4
Update 87/244, T 360448, FPS 213, 50-training-episode: mean/median 57.9/94.8, min/max -10.0/99.3
Update 88/244, T 364544, FPS 213, 50-training-episode: mean/median 56.5/95.9, min/max -7.6/106.4
Update 89/244, T 368640, FPS 213, 50-training-episode: mean/median 43.6/-2.9, min/max -8.2/98.4
Update 90/244, T 372736, FPS 213, 50-training-episode: mean/median 51.6/95.5, min/max -9.3/98.8
Update 91/244, T 376832, FPS 213, 50-training-episode: mean/median 37.7/-3.3, min/max -9.3/99.2
Update 92/244, T 380928, FPS 213, 50-training-episode: mean/median 33.0/-4.7, min/max -8.8/98.6
Update 93/244, T 385024, FPS 213, 50-training-episode: mean/median 39.1/-4.1, min/max -8.9/99.3
Update 94/244, T 389120, FPS 213, 50-training-episode: mean/median 45.7/46.0, min/max -8.5/99.3
Update 95/244, T 393216, FPS 213, 50-training-episode: mean/median 29.0/-4.1, min/max -9.2/99.2
Update 96/244, T 397312, FPS 213, 50-training-episode: mean/median 45.4/45.9, min/max -8.9/98.4
Update 97/244, T 401408, FPS 214, 50-training-episode: mean/median 53.6/95.3, min/max -8.9/98.4
Update 98/244, T 405504, FPS 214, 50-training-episode: mean/median 61.8/95.6, min/max -9.2/99.4
Update 99/244, T 409600, FPS 214, 50-training-episode: mean/median 49.4/93.9, min/max -11.4/99.4
Saved ./trained_models/ExptWalking20250729/plume_walk-v1_20250729_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.20.3_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed69361d.pt
Update 100/244, T 413696, FPS 213, 50-training-episode: mean/median 41.9/-2.4, min/max -9.3/98.8
Update 101/244, T 417792, FPS 213, 50-training-episode: mean/median 53.6/94.4, min/max -8.4/98.8
Update 102/244, T 421888, FPS 213, 50-training-episode: mean/median 51.5/94.3, min/max -11.2/99.4
Update 103/244, T 425984, FPS 213, 50-training-episode: mean/median 53.7/94.5, min/max -8.2/99.4
Update 104/244, T 430080, FPS 214, 50-training-episode: mean/median 57.5/95.2, min/max -8.6/99.1
Update 105/244, T 434176, FPS 214, 50-training-episode: mean/median 43.7/-2.5, min/max -10.6/99.1
Update 106/244, T 438272, FPS 214, 50-training-episode: mean/median 45.3/45.7, min/max -10.6/98.9
Update 107/244, T 442368, FPS 214, 50-training-episode: mean/median 31.0/-3.6, min/max -9.6/98.7
Update 108/244, T 446464, FPS 214, 50-training-episode: mean/median 35.3/-3.0, min/max -9.6/98.7
Update 109/244, T 450560, FPS 214, 50-training-episode: mean/median 29.7/-3.4, min/max -9.7/98.4
Update 110/244, T 454656, FPS 214, 50-training-episode: mean/median 20.9/-4.5, min/max -11.0/98.5
Update 111/244, T 458752, FPS 214, 50-training-episode: mean/median 22.8/-4.5, min/max -10.2/98.0
Update 112/244, T 462848, FPS 214, 50-training-episode: mean/median 27.2/-4.3, min/max -11.2/98.3
Update 113/244, T 466944, FPS 214, 50-training-episode: mean/median 34.7/-4.8, min/max -11.2/99.2
Update 114/244, T 471040, FPS 214, 50-training-episode: mean/median 38.8/-3.6, min/max -10.7/99.2
Update 115/244, T 475136, FPS 214, 50-training-episode: mean/median 34.8/-3.8, min/max -9.9/98.9
Update 116/244, T 479232, FPS 214, 50-training-episode: mean/median 32.7/-4.4, min/max -10.5/99.1
Update 117/244, T 483328, FPS 214, 50-training-episode: mean/median 33.0/-4.1, min/max -9.3/98.4
Update 118/244, T 487424, FPS 214, 50-training-episode: mean/median 30.6/-4.5, min/max -9.4/98.5
Update 119/244, T 491520, FPS 214, 50-training-episode: mean/median 6.1/-6.1, min/max -9.8/98.5
Update 120/244, T 495616, FPS 214, 50-training-episode: mean/median 12.1/-5.9, min/max -12.5/97.8
Update 121/244, T 499712, FPS 214, 50-training-episode: mean/median 30.6/-3.9, min/max -10.5/99.0
Update 122/244, T 503808, FPS 214, 50-training-episode: mean/median 41.2/-2.8, min/max -9.7/98.4
Update 123/244, T 507904, FPS 214, 50-training-episode: mean/median 39.0/-2.8, min/max -9.7/98.4
Update 124/244, T 512000, FPS 214, 50-training-episode: mean/median 53.2/94.3, min/max -9.1/98.9
Update 125/244, T 516096, FPS 214, 50-training-episode: mean/median 41.4/-2.8, min/max -8.3/98.6
Update 126/244, T 520192, FPS 214, 50-training-episode: mean/median 49.9/93.8, min/max -8.3/108.0
Update 127/244, T 524288, FPS 214, 50-training-episode: mean/median 41.0/-3.8, min/max -9.7/99.1
Update 128/244, T 528384, FPS 214, 50-training-episode: mean/median 30.2/-4.8, min/max -12.8/98.8
Update 129/244, T 532480, FPS 214, 50-training-episode: mean/median 34.4/-4.7, min/max -12.8/98.9
Update 130/244, T 536576, FPS 213, 50-training-episode: mean/median 41.5/-3.9, min/max -10.5/99.3
Update 131/244, T 540672, FPS 213, 50-training-episode: mean/median 35.1/-4.2, min/max -9.8/99.3
Update 132/244, T 544768, FPS 213, 50-training-episode: mean/median 38.9/-3.7, min/max -9.8/99.2
Update 133/244, T 548864, FPS 213, 50-training-episode: mean/median 37.3/-3.4, min/max -9.6/99.0
Update 134/244, T 552960, FPS 213, 50-training-episode: mean/median 39.2/-3.1, min/max -9.5/98.3
Update 135/244, T 557056, FPS 213, 50-training-episode: mean/median 49.1/93.3, min/max -10.1/99.5
Update 136/244, T 561152, FPS 213, 50-training-episode: mean/median 44.7/45.2, min/max -10.1/98.0
Update 137/244, T 565248, FPS 213, 50-training-episode: mean/median 50.9/93.6, min/max -10.1/98.2
Update 138/244, T 569344, FPS 213, 50-training-episode: mean/median 53.5/94.0, min/max -9.4/99.2
Update 139/244, T 573440, FPS 213, 50-training-episode: mean/median 57.7/94.8, min/max -10.6/99.2
Update 140/244, T 577536, FPS 213, 50-training-episode: mean/median 53.3/94.7, min/max -10.6/98.9
Update 141/244, T 581632, FPS 213, 50-training-episode: mean/median 45.0/45.1, min/max -10.1/99.1
Update 142/244, T 585728, FPS 213, 50-training-episode: mean/median 43.2/-3.4, min/max -9.6/99.1
Update 143/244, T 589824, FPS 213, 50-training-episode: mean/median 53.2/93.9, min/max -9.8/99.1
Update 144/244, T 593920, FPS 213, 50-training-episode: mean/median 45.4/50.0, min/max -9.8/99.2
Update 145/244, T 598016, FPS 213, 50-training-episode: mean/median 43.1/2.2, min/max -11.4/98.3
Update 146/244, T 602112, FPS 213, 50-training-episode: mean/median 40.6/-3.3, min/max -10.7/98.2
Update 147/244, T 606208, FPS 213, 50-training-episode: mean/median 45.2/50.1, min/max -10.4/98.7
Update 148/244, T 610304, FPS 213, 50-training-episode: mean/median 41.4/-3.1, min/max -9.5/98.7
Update 149/244, T 614400, FPS 213, 50-training-episode: mean/median 34.5/-4.3, min/max -12.0/105.3
Update 150/244, T 618496, FPS 213, 50-training-episode: mean/median 36.5/-4.0, min/max -12.0/105.3
Update 151/244, T 622592, FPS 213, 50-training-episode: mean/median 38.2/-4.1, min/max -10.5/98.8
Update 152/244, T 626688, FPS 214, 50-training-episode: mean/median 44.5/45.1, min/max -11.9/98.8
Update 153/244, T 630784, FPS 214, 50-training-episode: mean/median 44.4/44.6, min/max -14.9/98.1
Update 154/244, T 634880, FPS 214, 50-training-episode: mean/median 46.4/94.7, min/max -14.5/99.1
Update 155/244, T 638976, FPS 214, 50-training-episode: mean/median 50.9/95.1, min/max -12.8/99.1
Update 156/244, T 643072, FPS 214, 50-training-episode: mean/median 48.7/93.9, min/max -12.2/99.7
Update 157/244, T 647168, FPS 214, 50-training-episode: mean/median 59.2/95.8, min/max -11.7/99.7
Update 158/244, T 651264, FPS 214, 50-training-episode: mean/median 61.1/95.8, min/max -11.7/99.3
Update 159/244, T 655360, FPS 214, 50-training-episode: mean/median 48.3/93.9, min/max -13.0/99.3
Update 160/244, T 659456, FPS 214, 50-training-episode: mean/median 42.0/-3.6, min/max -11.9/99.3
Update 161/244, T 663552, FPS 214, 50-training-episode: mean/median 46.4/93.1, min/max -12.7/99.3
Update 162/244, T 667648, FPS 214, 50-training-episode: mean/median 50.7/94.0, min/max -11.4/98.4
Update 163/244, T 671744, FPS 214, 50-training-episode: mean/median 55.1/94.6, min/max -11.4/98.6
Update 164/244, T 675840, FPS 214, 50-training-episode: mean/median 50.6/93.1, min/max -11.1/99.2
Update 165/244, T 679936, FPS 214, 50-training-episode: mean/median 52.1/93.0, min/max -12.4/99.2
Update 166/244, T 684032, FPS 214, 50-training-episode: mean/median 46.3/92.8, min/max -11.2/99.2
Update 167/244, T 688128, FPS 214, 50-training-episode: mean/median 38.4/-4.4, min/max -13.1/99.2
Update 168/244, T 692224, FPS 214, 50-training-episode: mean/median 35.8/-4.5, min/max -13.3/99.0
Update 169/244, T 696320, FPS 214, 50-training-episode: mean/median 37.5/-4.5, min/max -13.3/98.1
Update 170/244, T 700416, FPS 214, 50-training-episode: mean/median 33.5/-5.0, min/max -13.2/98.7
Update 171/244, T 704512, FPS 214, 50-training-episode: mean/median 33.8/-5.1, min/max -14.7/99.2
Update 172/244, T 708608, FPS 214, 50-training-episode: mean/median 33.5/-5.5, min/max -14.7/98.7
Update 173/244, T 712704, FPS 214, 50-training-episode: mean/median 46.7/91.7, min/max -12.7/107.5
Update 174/244, T 716800, FPS 214, 50-training-episode: mean/median 45.0/44.7, min/max -12.2/107.5
Update 175/244, T 720896, FPS 214, 50-training-episode: mean/median 34.1/-4.5, min/max -12.6/98.7
Update 176/244, T 724992, FPS 214, 50-training-episode: mean/median 46.1/93.9, min/max -13.4/99.4
Update 177/244, T 729088, FPS 214, 50-training-episode: mean/median 54.8/95.4, min/max -13.4/99.6
Update 178/244, T 733184, FPS 214, 50-training-episode: mean/median 60.8/94.7, min/max -16.1/99.6
Update 179/244, T 737280, FPS 214, 50-training-episode: mean/median 44.0/45.6, min/max -16.1/99.8
Update 180/244, T 741376, FPS 214, 50-training-episode: mean/median 46.4/94.2, min/max -13.9/99.8
Update 181/244, T 745472, FPS 214, 50-training-episode: mean/median 46.1/93.0, min/max -13.9/99.1
Update 182/244, T 749568, FPS 214, 50-training-episode: mean/median 37.4/-4.5, min/max -12.7/98.4
Update 183/244, T 753664, FPS 214, 50-training-episode: mean/median 39.4/-5.1, min/max -16.5/99.4
Update 184/244, T 757760, FPS 214, 50-training-episode: mean/median 37.5/-4.5, min/max -16.5/99.4
Update 185/244, T 761856, FPS 214, 50-training-episode: mean/median 39.5/-3.9, min/max -17.2/98.8
Update 186/244, T 765952, FPS 214, 50-training-episode: mean/median 38.2/-4.9, min/max -16.9/99.3
Update 187/244, T 770048, FPS 214, 50-training-episode: mean/median 50.9/95.4, min/max -13.5/99.0
Update 188/244, T 774144, FPS 214, 50-training-episode: mean/median 56.7/95.6, min/max -14.2/99.7
Update 189/244, T 778240, FPS 214, 50-training-episode: mean/median 56.5/95.0, min/max -14.3/99.7
Update 190/244, T 782336, FPS 215, 50-training-episode: mean/median 45.6/93.5, min/max -17.8/99.4
Update 191/244, T 786432, FPS 215, 50-training-episode: mean/median 45.6/93.7, min/max -17.8/98.8
Update 192/244, T 790528, FPS 215, 50-training-episode: mean/median 56.5/94.2, min/max -14.2/98.8
Update 193/244, T 794624, FPS 215, 50-training-episode: mean/median 56.5/94.5, min/max -13.9/98.8
Update 194/244, T 798720, FPS 215, 50-training-episode: mean/median 58.0/95.7, min/max -16.6/99.0
Update 195/244, T 802816, FPS 215, 50-training-episode: mean/median 60.1/95.7, min/max -16.6/99.0
Update 196/244, T 806912, FPS 215, 50-training-episode: mean/median 51.8/94.4, min/max -16.2/99.0
Update 197/244, T 811008, FPS 215, 50-training-episode: mean/median 47.4/93.4, min/max -15.2/99.0
Update 198/244, T 815104, FPS 215, 50-training-episode: mean/median 52.4/94.6, min/max -15.0/98.3
Update 199/244, T 819200, FPS 215, 50-training-episode: mean/median 46.6/95.0, min/max -14.8/108.5
Saved ./trained_models/ExptWalking20250729/plume_walk-v1_20250729_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.20.3_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed69361d.pt
Saved ./trained_models/ExptWalking20250729/plume_walk-v1_20250729_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.20.3_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed69361d.pt.best
Update 200/244, T 823296, FPS 215, 50-training-episode: mean/median 46.6/94.6, min/max -12.8/99.4
Update 201/244, T 827392, FPS 215, 50-training-episode: mean/median 52.5/95.5, min/max -15.0/99.2
Update 202/244, T 831488, FPS 215, 50-training-episode: mean/median 48.3/95.0, min/max -15.0/99.1
Update 203/244, T 835584, FPS 215, 50-training-episode: mean/median 56.6/94.1, min/max -14.1/103.8
Update 204/244, T 839680, FPS 215, 50-training-episode: mean/median 56.9/95.5, min/max -13.1/99.5
Update 205/244, T 843776, FPS 215, 50-training-episode: mean/median 63.3/95.8, min/max -13.1/99.3
Update 206/244, T 847872, FPS 215, 50-training-episode: mean/median 61.2/94.7, min/max -11.9/99.1
Update 207/244, T 851968, FPS 215, 50-training-episode: mean/median 57.1/94.7, min/max -14.5/99.1
Update 208/244, T 856064, FPS 215, 50-training-episode: mean/median 42.2/-3.1, min/max -14.5/98.5
Update 209/244, T 860160, FPS 215, 50-training-episode: mean/median 46.4/93.9, min/max -12.4/99.2
Update 210/244, T 864256, FPS 215, 50-training-episode: mean/median 46.2/94.0, min/max -12.4/98.9
Update 211/244, T 868352, FPS 215, 50-training-episode: mean/median 52.1/94.7, min/max -12.0/99.1
Update 212/244, T 872448, FPS 215, 50-training-episode: mean/median 69.4/95.6, min/max -12.1/99.1
Update 213/244, T 876544, FPS 215, 50-training-episode: mean/median 63.6/95.5, min/max -12.2/99.3
Update 214/244, T 880640, FPS 215, 50-training-episode: mean/median 48.8/94.4, min/max -12.7/99.3
Update 215/244, T 884736, FPS 215, 50-training-episode: mean/median 50.5/94.1, min/max -12.7/99.3
Update 216/244, T 888832, FPS 215, 50-training-episode: mean/median 65.2/95.2, min/max -12.0/99.3
Update 217/244, T 892928, FPS 215, 50-training-episode: mean/median 63.2/95.4, min/max -12.7/98.4
Update 218/244, T 897024, FPS 215, 50-training-episode: mean/median 62.8/95.1, min/max -11.4/98.3
Update 219/244, T 901120, FPS 215, 50-training-episode: mean/median 61.1/94.9, min/max -12.4/99.1
Update 220/244, T 905216, FPS 215, 50-training-episode: mean/median 48.2/94.3, min/max -16.2/99.1
Update 221/244, T 909312, FPS 215, 50-training-episode: mean/median 47.9/93.7, min/max -16.2/99.2
Update 222/244, T 913408, FPS 215, 50-training-episode: mean/median 61.0/95.7, min/max -14.0/99.2
Update 223/244, T 917504, FPS 215, 50-training-episode: mean/median 58.4/95.7, min/max -15.1/98.9
Update 224/244, T 921600, FPS 215, 50-training-episode: mean/median 67.2/96.3, min/max -13.5/108.3
Update 225/244, T 925696, FPS 215, 50-training-episode: mean/median 67.2/96.2, min/max -12.8/108.3
Update 226/244, T 929792, FPS 215, 50-training-episode: mean/median 77.8/96.3, min/max -12.6/99.5
Update 227/244, T 933888, FPS 215, 50-training-episode: mean/median 65.4/95.4, min/max -12.6/99.5
Update 228/244, T 937984, FPS 215, 50-training-episode: mean/median 69.2/95.5, min/max -11.8/98.9
Update 229/244, T 942080, FPS 215, 50-training-episode: mean/median 67.2/95.8, min/max -11.2/106.0
Update 230/244, T 946176, FPS 215, 50-training-episode: mean/median 65.2/95.3, min/max -11.1/106.0
Update 231/244, T 950272, FPS 215, 50-training-episode: mean/median 61.1/94.2, min/max -11.4/98.6
Update 232/244, T 954368, FPS 215, 50-training-episode: mean/median 61.3/95.5, min/max -10.6/98.6
Update 233/244, T 958464, FPS 215, 50-training-episode: mean/median 69.8/95.9, min/max -10.8/99.4
Update 234/244, T 962560, FPS 215, 50-training-episode: mean/median 73.9/96.0, min/max -10.8/99.3
Update 235/244, T 966656, FPS 215, 50-training-episode: mean/median 71.3/95.4, min/max -11.8/98.9
Update 236/244, T 970752, FPS 215, 50-training-episode: mean/median 69.4/96.5, min/max -11.8/98.9
Update 237/244, T 974848, FPS 215, 50-training-episode: mean/median 48.8/94.4, min/max -11.8/99.1
Update 238/244, T 978944, FPS 215, 50-training-episode: mean/median 48.6/94.2, min/max -11.9/98.9
Update 239/244, T 983040, FPS 215, 50-training-episode: mean/median 61.2/95.5, min/max -12.8/108.8
Update 240/244, T 987136, FPS 215, 50-training-episode: mean/median 59.7/95.7, min/max -12.8/108.8
Update 241/244, T 991232, FPS 215, 50-training-episode: mean/median 61.2/95.5, min/max -14.0/99.1
Update 242/244, T 995328, FPS 215, 50-training-episode: mean/median 61.2/95.9, min/max -12.7/99.2
Saved ./trained_models/ExptWalking20250729/plume_walk-v1_20250729_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.20.3_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed69361d.pt
Saved ./trained_models/ExptWalking20250729/plume_walk-v1_20250729_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.20.3_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed69361d.pt.best
Update 243/244, T 999424, FPS 215, 50-training-episode: mean/median 54.6/95.7, min/max -13.0/99.2
Stage: 1/2 - noisy3x5b5 b4.0 q0.3 n200000
Using Precomputed Plume...
Using Precomputed Plume...
2025-07-30 00:42:00.340 python[94110:52477149] +[NSXPCSharedListener endpointForReply:withListenerName:replyErrorCode:]: an error occurred while attempting to obtain endpoint for listener 'ClientCallsAuxiliary': Connection invalid
2025-07-30 00:42:00.340 python[94109:52477148] +[NSXPCSharedListener endpointForReply:withListenerName:replyErrorCode:]: an error occurred while attempting to obtain endpoint for listener 'ClientCallsAuxiliary': Connection invalid
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x102dab220>, 't_val_min': 10.0, 'sim_steps_max': 2000, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 3.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.2, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.7, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': True, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 6936, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x102dab220>, 't_val_min': 10.0, 'sim_steps_max': 2000, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 3.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.2, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.7, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': True, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 6936, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
Saved ./trained_models/ExptWalking20250729/plume_walk-v1_20250729_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.20.3_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed69361d.pt
Update 0/48, T 4096, FPS 120, 50-training-episode: mean/median -1.8/-1.5, min/max -11.3/7.6
Update 1/48, T 8192, FPS 124, 50-training-episode: mean/median 3.9/-1.5, min/max -5.4/97.0
Update 2/48, T 12288, FPS 125, 50-training-episode: mean/median -2.1/-1.3, min/max -10.0/-0.7
Update 3/48, T 16384, FPS 126, 50-training-episode: mean/median -2.1/-1.4, min/max -9.5/5.8
Update 4/48, T 20480, FPS 127, 50-training-episode: mean/median -2.0/-1.4, min/max -9.9/-0.2
Update 5/48, T 24576, FPS 127, 50-training-episode: mean/median 2.4/-1.3, min/max -5.8/107.6
Update 6/48, T 28672, FPS 128, 50-training-episode: mean/median 8.1/-1.5, min/max -8.9/105.1
Update 7/48, T 32768, FPS 129, 50-training-episode: mean/median 4.3/-1.4, min/max -10.1/104.1
Update 8/48, T 36864, FPS 129, 50-training-episode: mean/median 2.0/-1.4, min/max -11.6/107.7
Update 9/48, T 40960, FPS 130, 50-training-episode: mean/median 2.2/-1.3, min/max -6.4/98.2
Update 10/48, T 45056, FPS 131, 50-training-episode: mean/median 1.9/-1.5, min/max -13.1/106.7
Update 11/48, T 49152, FPS 130, 50-training-episode: mean/median 0.1/-1.3, min/max -13.9/96.7
Update 12/48, T 53248, FPS 131, 50-training-episode: mean/median 2.2/-1.4, min/max -12.4/107.4
Update 13/48, T 57344, FPS 131, 50-training-episode: mean/median -2.3/-1.5, min/max -12.8/-0.7
Update 14/48, T 61440, FPS 132, 50-training-episode: mean/median 0.1/-1.6, min/max -7.3/97.5
Update 15/48, T 65536, FPS 132, 50-training-episode: mean/median -1.7/-1.3, min/max -13.1/9.0
Update 16/48, T 69632, FPS 132, 50-training-episode: mean/median 1.7/-1.4, min/max -13.3/98.9
Update 17/48, T 73728, FPS 133, 50-training-episode: mean/median 3.0/-1.5, min/max -14.5/96.1
Update 18/48, T 77824, FPS 133, 50-training-episode: mean/median 4.5/-1.2, min/max -8.8/98.3
Update 19/48, T 81920, FPS 133, 50-training-episode: mean/median -2.1/-1.4, min/max -12.0/4.7
Update 20/48, T 86016, FPS 133, 50-training-episode: mean/median 0.1/-1.4, min/max -8.2/93.7
Update 21/48, T 90112, FPS 133, 50-training-episode: mean/median 6.2/-1.4, min/max -8.2/102.0
Update 22/48, T 94208, FPS 133, 50-training-episode: mean/median 8.0/-1.5, min/max -9.0/98.6
Update 23/48, T 98304, FPS 134, 50-training-episode: mean/median 3.6/-1.4, min/max -14.4/95.9
Update 24/48, T 102400, FPS 135, 50-training-episode: mean/median 4.0/-1.5, min/max -12.8/103.3
Update 25/48, T 106496, FPS 135, 50-training-episode: mean/median -0.4/-1.5, min/max -16.2/98.0
Update 26/48, T 110592, FPS 135, 50-training-episode: mean/median 6.0/-1.4, min/max -9.3/99.1
Update 27/48, T 114688, FPS 134, 50-training-episode: mean/median 6.3/-1.4, min/max -12.1/108.0
Update 28/48, T 118784, FPS 134, 50-training-episode: mean/median 1.8/-1.5, min/max -9.6/96.0
Update 29/48, T 122880, FPS 135, 50-training-episode: mean/median 7.4/-1.5, min/max -13.6/98.8
Update 30/48, T 126976, FPS 135, 50-training-episode: mean/median 1.6/-1.6, min/max -17.2/96.3
Update 31/48, T 131072, FPS 135, 50-training-episode: mean/median 4.1/-1.2, min/max -17.8/96.3
Update 32/48, T 135168, FPS 135, 50-training-episode: mean/median 1.2/-1.6, min/max -14.5/96.8
Update 33/48, T 139264, FPS 135, 50-training-episode: mean/median 7.5/-1.3, min/max -19.0/107.9
Update 34/48, T 143360, FPS 135, 50-training-episode: mean/median 2.0/-1.3, min/max -18.4/96.5
Update 35/48, T 147456, FPS 135, 50-training-episode: mean/median 1.6/-1.3, min/max -12.6/95.4
Update 36/48, T 151552, FPS 135, 50-training-episode: mean/median 8.1/-1.4, min/max -11.0/106.2
Update 37/48, T 155648, FPS 135, 50-training-episode: mean/median 2.1/-1.4, min/max -10.2/95.9
Update 38/48, T 159744, FPS 136, 50-training-episode: mean/median 4.6/-1.3, min/max -5.4/103.7
Update 39/48, T 163840, FPS 136, 50-training-episode: mean/median 3.6/-1.5, min/max -11.1/97.8
Update 40/48, T 167936, FPS 135, 50-training-episode: mean/median 3.8/-1.5, min/max -18.5/95.9
Update 41/48, T 172032, FPS 135, 50-training-episode: mean/median 4.4/-1.3, min/max -3.5/95.3
Update 42/48, T 176128, FPS 135, 50-training-episode: mean/median -0.1/-1.4, min/max -11.7/97.8
Update 43/48, T 180224, FPS 135, 50-training-episode: mean/median 9.8/-1.4, min/max -12.9/105.2
Update 44/48, T 184320, FPS 135, 50-training-episode: mean/median -1.9/-1.5, min/max -10.6/6.2
Update 45/48, T 188416, FPS 135, 50-training-episode: mean/median 4.0/-1.3, min/max -9.5/95.9
Update 46/48, T 192512, FPS 135, 50-training-episode: mean/median 4.2/-1.5, min/max -8.9/98.7
Saved ./trained_models/ExptWalking20250729/plume_walk-v1_20250729_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.20.3_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed69361d.pt
Update 47/48, T 196608, FPS 135, 50-training-episode: mean/median 3.9/-1.4, min/max -13.0/99.0
Saved ./trained_models/ExptWalking20250729//plume_walk-v1_20250729_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.20.3_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed69361d.pt
Starting evaluation
Evaluating on dataset: switch15x5b5
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x17ba4f970>, 't_val_min': 10.0, 'sim_steps_max': 2000, 'reset_offset_tmax': 30, 'dataset': 'switch15x5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 6936, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
switch15x5b5
Exception: [Errno 2] No such file or directory: '/Users/aaravsinha/plume/plumedata//puff_data_switch15x5b5.pickle'
Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 271, in eval_loop
    env = make_vec_envs(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 132, in make_vec_envs
    envs = DummyVecEnv(envs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 26, in __init__
    self.envs = [fn() for fn in env_fns]
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 26, in <listcomp>
    self.envs = [fn() for fn in env_fns]
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 34, in _thunk
    env = plume_env.PlumeEnvironment(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 116, in __init__
    self.set_dataset(dataset)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 205, in set_dataset
    self.data_puffs_all, self.data_wind_all = sim_analysis.load_plume(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 173, in load_plume
    data_puffs = pandas.read_pickle(puff_filename)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/pickle.py", line 185, in read_pickle
    with get_handle(
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/aaravsinha/plume/plumedata//puff_data_switch15x5b5.pickle'
Evaluating on dataset: switch30x5b5
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x17ba4fcd0>, 't_val_min': 10.0, 'sim_steps_max': 2000, 'reset_offset_tmax': 30, 'dataset': 'switch30x5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 6936, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
switch30x5b5
Exception: [Errno 2] No such file or directory: '/Users/aaravsinha/plume/plumedata//puff_data_switch30x5b5.pickle'
Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 271, in eval_loop
    env = make_vec_envs(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 132, in make_vec_envs
    envs = DummyVecEnv(envs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 26, in __init__
    self.envs = [fn() for fn in env_fns]
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 26, in <listcomp>
    self.envs = [fn() for fn in env_fns]
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 34, in _thunk
    env = plume_env.PlumeEnvironment(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 116, in __init__
    self.set_dataset(dataset)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 205, in set_dataset
    self.data_puffs_all, self.data_wind_all = sim_analysis.load_plume(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 173, in load_plume
    data_puffs = pandas.read_pickle(puff_filename)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/pickle.py", line 185, in read_pickle
    with get_handle(
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/aaravsinha/plume/plumedata//puff_data_switch30x5b5.pickle'
Evaluating on dataset: switch45x5b5
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x17ba4fc70>, 't_val_min': 10.0, 'sim_steps_max': 2000, 'reset_offset_tmax': 30, 'dataset': 'switch45x5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 6936, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
switch45x5b5
Exception: [Errno 2] No such file or directory: '/Users/aaravsinha/plume/plumedata//puff_data_switch45x5b5.pickle'
Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 271, in eval_loop
    env = make_vec_envs(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 132, in make_vec_envs
    envs = DummyVecEnv(envs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 26, in __init__
    self.envs = [fn() for fn in env_fns]
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 26, in <listcomp>
    self.envs = [fn() for fn in env_fns]
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 34, in _thunk
    env = plume_env.PlumeEnvironment(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 116, in __init__
    self.set_dataset(dataset)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 205, in set_dataset
    self.data_puffs_all, self.data_wind_all = sim_analysis.load_plume(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 173, in load_plume
    data_puffs = pandas.read_pickle(puff_filename)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/pickle.py", line 185, in read_pickle
    with get_handle(
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/aaravsinha/plume/plumedata//puff_data_switch45x5b5.pickle'
Evaluating on dataset: constantx5b5
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x17ba4f910>, 't_val_min': 10.0, 'sim_steps_max': 2000, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 6936, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
Using fixed evaluation sequence [time, angle, loc_y]... (240 episodes) 
Episode: 0, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 1, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 2, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 3, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 4, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 5, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 6, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 7, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 8, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 9, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 10, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 11, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 12, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 13, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 14, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 15, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 16, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 17, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 18, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 19, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 20, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 21, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 22, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 23, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 24, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 25, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 26, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 27, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 28, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 29, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 30, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 31, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 32, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 33, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 34, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 35, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 36, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 37, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 38, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 39, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 40, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 41, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 42, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 43, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 44, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 45, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 46, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 47, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 48, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 49, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 50, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 51, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 52, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 53, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 54, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 55, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 56, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 57, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 58, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 59, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 60, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 61, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 62, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 63, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 64, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 65, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 66, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 67, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 68, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 69, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 70, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 71, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 72, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 73, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 74, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 75, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 76, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 77, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 78, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 79, reward_sum: -10.0, Steps: 1, Reason: OOB
Exception: name 'nan' is not defined
Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 231, in resolve
    return self.resolvers[key]
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'nan'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 242, in resolve
    return self.temps[key]
KeyError: 'nan'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 289, in eval_loop
    episode_logs, episode_summaries = evaluate_agent(actor_critic, env, args)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 180, in evaluate_agent
    obs = env.reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 208, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/vec_normalize.py", line 284, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 74, in reset
    obs = self.envs[env_idx].reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 448, in reset
    observation = self.sense_environment()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 269, in sense_environment
    odor_observation = sim_analysis.get_concentration_at_tidx(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 263, in get_concentration_at_tidx
    d = data[data.tidx==tidx].query(q)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4828, in query
    res = self.eval(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4954, in eval
    return _eval(expr, inplace=inplace, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/eval.py", line 339, in eval
    parsed_expr = Expr(expr, engine=engine, parser=parser, env=env)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 809, in __init__
    self.terms = self.parse()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 828, in parse
    return self._visitor.visit(self.expr)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 419, in visit_Module
    return self.visit(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 422, in visit_Expr
    return self.visit(node.value, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 746, in visit_BoolOp
    return reduce(visitor, operands)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 740, in visitor
    rhs = self._try_visit_binop(y)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 735, in _try_visit_binop
    return self.visit(bop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 719, in visit_Compare
    return self.visit(binop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 535, in visit_BinOp
    op, op_class, left, right = self._maybe_transform_eq_ne(node)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 453, in _maybe_transform_eq_ne
    left = self.visit(node.left, side="left")
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 545, in visit_Name
    return self.term_type(node.id, self.env, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 91, in __init__
    self._value = self._resolve_name()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 115, in _resolve_name
    res = self.env.resolve(local_name, is_local=is_local)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 244, in resolve
    raise UndefinedVariableError(key, is_local) from err
pandas.errors.UndefinedVariableError: name 'nan' is not defined
Sparse/birthx: 0.8
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x17ba4ff70>, 't_val_min': 10.0, 'sim_steps_max': 2000, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 0.8, 'env_dt': 0.04, 'loc_algo': 'quantile', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 6936, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
Sparsifying puffs to 0.8x
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
Using fixed evaluation sequence [time, angle, loc_y]... (240 episodes) 
Exception: name 'nan' is not defined
Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 231, in resolve
    return self.resolvers[key]
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'nan'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 242, in resolve
    return self.temps[key]
KeyError: 'nan'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 363, in eval_loop
    episode_logs, episode_summaries = evaluate_agent(actor_critic, env, args)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 180, in evaluate_agent
    obs = env.reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 208, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/vec_normalize.py", line 284, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 74, in reset
    obs = self.envs[env_idx].reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 448, in reset
    observation = self.sense_environment()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 269, in sense_environment
    odor_observation = sim_analysis.get_concentration_at_tidx(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 263, in get_concentration_at_tidx
    d = data[data.tidx==tidx].query(q)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4828, in query
    res = self.eval(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4954, in eval
    return _eval(expr, inplace=inplace, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/eval.py", line 339, in eval
    parsed_expr = Expr(expr, engine=engine, parser=parser, env=env)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 809, in __init__
    self.terms = self.parse()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 828, in parse
    return self._visitor.visit(self.expr)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 419, in visit_Module
    return self.visit(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 422, in visit_Expr
    return self.visit(node.value, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 746, in visit_BoolOp
    return reduce(visitor, operands)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 740, in visitor
    rhs = self._try_visit_binop(y)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 735, in _try_visit_binop
    return self.visit(bop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 719, in visit_Compare
    return self.visit(binop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 535, in visit_BinOp
    op, op_class, left, right = self._maybe_transform_eq_ne(node)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 453, in _maybe_transform_eq_ne
    left = self.visit(node.left, side="left")
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 545, in visit_Name
    return self.term_type(node.id, self.env, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 91, in __init__
    self._value = self._resolve_name()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 115, in _resolve_name
    res = self.env.resolve(local_name, is_local=is_local)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 244, in resolve
    raise UndefinedVariableError(key, is_local) from err
pandas.errors.UndefinedVariableError: name 'nan' is not defined
Sparse/birthx: 0.6
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x1766afeb0>, 't_val_min': 10.0, 'sim_steps_max': 2000, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 0.6, 'env_dt': 0.04, 'loc_algo': 'quantile', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 6936, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
Sparsifying puffs to 0.6x
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
Using fixed evaluation sequence [time, angle, loc_y]... (240 episodes) 
Episode: 0, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 1, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 2, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 3, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 4, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 5, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 6, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 7, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 8, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 9, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 10, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 11, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 12, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 13, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 14, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 15, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 16, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 17, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 18, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 19, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 20, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 21, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 22, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 23, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 24, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 25, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 26, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 27, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 28, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 29, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 30, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 31, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 32, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 33, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 34, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 35, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 36, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 37, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 38, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 39, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 40, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 41, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 42, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 43, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 44, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 45, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 46, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 47, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 48, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 49, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 50, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 51, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 52, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 53, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 54, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 55, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 56, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 57, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 58, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 59, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 60, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 61, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 62, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 63, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 64, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 65, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 66, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 67, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 68, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 69, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 70, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 71, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 72, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 73, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 74, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 75, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 76, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 77, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 78, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 79, reward_sum: -10.0, Steps: 1, Reason: OOB
Exception: name 'nan' is not defined
Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 231, in resolve
    return self.resolvers[key]
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'nan'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 242, in resolve
    return self.temps[key]
KeyError: 'nan'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 363, in eval_loop
    episode_logs, episode_summaries = evaluate_agent(actor_critic, env, args)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 180, in evaluate_agent
    obs = env.reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 208, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/vec_normalize.py", line 284, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 74, in reset
    obs = self.envs[env_idx].reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 448, in reset
    observation = self.sense_environment()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 269, in sense_environment
    odor_observation = sim_analysis.get_concentration_at_tidx(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 263, in get_concentration_at_tidx
    d = data[data.tidx==tidx].query(q)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4828, in query
    res = self.eval(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4954, in eval
    return _eval(expr, inplace=inplace, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/eval.py", line 339, in eval
    parsed_expr = Expr(expr, engine=engine, parser=parser, env=env)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 809, in __init__
    self.terms = self.parse()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 828, in parse
    return self._visitor.visit(self.expr)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 419, in visit_Module
    return self.visit(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 422, in visit_Expr
    return self.visit(node.value, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 746, in visit_BoolOp
    return reduce(visitor, operands)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 740, in visitor
    rhs = self._try_visit_binop(y)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 735, in _try_visit_binop
    return self.visit(bop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 719, in visit_Compare
    return self.visit(binop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 535, in visit_BinOp
    op, op_class, left, right = self._maybe_transform_eq_ne(node)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 453, in _maybe_transform_eq_ne
    left = self.visit(node.left, side="left")
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 545, in visit_Name
    return self.term_type(node.id, self.env, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 91, in __init__
    self._value = self._resolve_name()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 115, in _resolve_name
    res = self.env.resolve(local_name, is_local=is_local)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 244, in resolve
    raise UndefinedVariableError(key, is_local) from err
pandas.errors.UndefinedVariableError: name 'nan' is not defined
Sparse/birthx: 0.4
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x16e132610>, 't_val_min': 10.0, 'sim_steps_max': 2000, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 0.4, 'env_dt': 0.04, 'loc_algo': 'quantile', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 6936, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
Sparsifying puffs to 0.4x
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
Using fixed evaluation sequence [time, angle, loc_y]... (240 episodes) 
Episode: 0, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 1, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 2, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 3, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 4, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 5, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 6, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 7, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 8, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 9, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 10, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 11, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 12, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 13, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 14, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 15, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 16, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 17, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 18, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 19, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 20, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 21, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 22, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 23, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 24, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 25, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 26, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 27, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 28, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 29, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 30, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 31, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 32, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 33, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 34, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 35, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 36, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 37, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 38, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 39, reward_sum: -10.0, Steps: 1, Reason: OOB
Exception: name 'nan' is not defined
Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 231, in resolve
    return self.resolvers[key]
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'nan'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 242, in resolve
    return self.temps[key]
KeyError: 'nan'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 363, in eval_loop
    episode_logs, episode_summaries = evaluate_agent(actor_critic, env, args)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 180, in evaluate_agent
    obs = env.reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 208, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/vec_normalize.py", line 284, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 74, in reset
    obs = self.envs[env_idx].reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 448, in reset
    observation = self.sense_environment()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 269, in sense_environment
    odor_observation = sim_analysis.get_concentration_at_tidx(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 263, in get_concentration_at_tidx
    d = data[data.tidx==tidx].query(q)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4828, in query
    res = self.eval(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4954, in eval
    return _eval(expr, inplace=inplace, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/eval.py", line 339, in eval
    parsed_expr = Expr(expr, engine=engine, parser=parser, env=env)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 809, in __init__
    self.terms = self.parse()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 828, in parse
    return self._visitor.visit(self.expr)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 419, in visit_Module
    return self.visit(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 422, in visit_Expr
    return self.visit(node.value, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 746, in visit_BoolOp
    return reduce(visitor, operands)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 740, in visitor
    rhs = self._try_visit_binop(y)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 735, in _try_visit_binop
    return self.visit(bop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 719, in visit_Compare
    return self.visit(binop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 535, in visit_BinOp
    op, op_class, left, right = self._maybe_transform_eq_ne(node)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 453, in _maybe_transform_eq_ne
    left = self.visit(node.left, side="left")
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 545, in visit_Name
    return self.term_type(node.id, self.env, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 91, in __init__
    self._value = self._resolve_name()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 115, in _resolve_name
    res = self.env.resolve(local_name, is_local=is_local)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 244, in resolve
    raise UndefinedVariableError(key, is_local) from err
pandas.errors.UndefinedVariableError: name 'nan' is not defined
Sparse/birthx: 0.2
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x177105580>, 't_val_min': 10.0, 'sim_steps_max': 2000, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 0.2, 'env_dt': 0.04, 'loc_algo': 'quantile', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 6936, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
Sparsifying puffs to 0.2x
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
Using fixed evaluation sequence [time, angle, loc_y]... (240 episodes) 
Episode: 0, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 1, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 2, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 3, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 4, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 5, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 6, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 7, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 8, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 9, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 10, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 11, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 12, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 13, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 14, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 15, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 16, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 17, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 18, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 19, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 20, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 21, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 22, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 23, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 24, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 25, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 26, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 27, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 28, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 29, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 30, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 31, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 32, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 33, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 34, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 35, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 36, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 37, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 38, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 39, reward_sum: -10.0, Steps: 1, Reason: OOB
Exception: name 'nan' is not defined
Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 231, in resolve
    return self.resolvers[key]
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'nan'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 242, in resolve
    return self.temps[key]
KeyError: 'nan'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 363, in eval_loop
    episode_logs, episode_summaries = evaluate_agent(actor_critic, env, args)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 180, in evaluate_agent
    obs = env.reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 208, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/vec_normalize.py", line 284, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 74, in reset
    obs = self.envs[env_idx].reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 448, in reset
    observation = self.sense_environment()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 269, in sense_environment
    odor_observation = sim_analysis.get_concentration_at_tidx(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 263, in get_concentration_at_tidx
    d = data[data.tidx==tidx].query(q)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4828, in query
    res = self.eval(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4954, in eval
    return _eval(expr, inplace=inplace, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/eval.py", line 339, in eval
    parsed_expr = Expr(expr, engine=engine, parser=parser, env=env)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 809, in __init__
    self.terms = self.parse()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 828, in parse
    return self._visitor.visit(self.expr)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 419, in visit_Module
    return self.visit(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 422, in visit_Expr
    return self.visit(node.value, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 746, in visit_BoolOp
    return reduce(visitor, operands)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 740, in visitor
    rhs = self._try_visit_binop(y)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 735, in _try_visit_binop
    return self.visit(bop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 719, in visit_Compare
    return self.visit(binop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 535, in visit_BinOp
    op, op_class, left, right = self._maybe_transform_eq_ne(node)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 453, in _maybe_transform_eq_ne
    left = self.visit(node.left, side="left")
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 545, in visit_Name
    return self.term_type(node.id, self.env, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 91, in __init__
    self._value = self._resolve_name()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 115, in _resolve_name
    res = self.env.resolve(local_name, is_local=is_local)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 244, in resolve
    raise UndefinedVariableError(key, is_local) from err
pandas.errors.UndefinedVariableError: name 'nan' is not defined
Evaluating on dataset: noisy3x5b5
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x17ba5ea60>, 't_val_min': 10.0, 'sim_steps_max': 2000, 'reset_offset_tmax': 30, 'dataset': 'noisy3x5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 0.2, 'env_dt': 0.04, 'loc_algo': 'quantile', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 6936, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
noisy3x5b5
Sparsifying puffs to 0.2x
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
Using fixed evaluation sequence [time, angle, loc_y]... (240 episodes) 
Exception: name 'nan' is not defined
Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 231, in resolve
    return self.resolvers[key]
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'nan'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 242, in resolve
    return self.temps[key]
KeyError: 'nan'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 289, in eval_loop
    episode_logs, episode_summaries = evaluate_agent(actor_critic, env, args)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 180, in evaluate_agent
    obs = env.reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 208, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/vec_normalize.py", line 284, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 74, in reset
    obs = self.envs[env_idx].reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 448, in reset
    observation = self.sense_environment()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 269, in sense_environment
    odor_observation = sim_analysis.get_concentration_at_tidx(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 263, in get_concentration_at_tidx
    d = data[data.tidx==tidx].query(q)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4828, in query
    res = self.eval(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4954, in eval
    return _eval(expr, inplace=inplace, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/eval.py", line 339, in eval
    parsed_expr = Expr(expr, engine=engine, parser=parser, env=env)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 809, in __init__
    self.terms = self.parse()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 828, in parse
    return self._visitor.visit(self.expr)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 419, in visit_Module
    return self.visit(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 422, in visit_Expr
    return self.visit(node.value, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 746, in visit_BoolOp
    return reduce(visitor, operands)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 740, in visitor
    rhs = self._try_visit_binop(y)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 735, in _try_visit_binop
    return self.visit(bop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 719, in visit_Compare
    return self.visit(binop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 535, in visit_BinOp
    op, op_class, left, right = self._maybe_transform_eq_ne(node)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 453, in _maybe_transform_eq_ne
    left = self.visit(node.left, side="left")
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 545, in visit_Name
    return self.term_type(node.id, self.env, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 91, in __init__
    self._value = self._resolve_name()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 115, in _resolve_name
    res = self.env.resolve(local_name, is_local=is_local)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 244, in resolve
    raise UndefinedVariableError(key, is_local) from err
pandas.errors.UndefinedVariableError: name 'nan' is not defined
Evaluating on dataset: noisy6x5b5
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x17ba4fd90>, 't_val_min': 10.0, 'sim_steps_max': 2000, 'reset_offset_tmax': 30, 'dataset': 'noisy6x5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 0.2, 'env_dt': 0.04, 'loc_algo': 'quantile', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 6936, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
noisy6x5b5
Exception: [Errno 2] No such file or directory: '/Users/aaravsinha/plume/plumedata//puff_data_noisy6x5b5.pickle'
Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 271, in eval_loop
    env = make_vec_envs(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 132, in make_vec_envs
    envs = DummyVecEnv(envs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 26, in __init__
    self.envs = [fn() for fn in env_fns]
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 26, in <listcomp>
    self.envs = [fn() for fn in env_fns]
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 34, in _thunk
    env = plume_env.PlumeEnvironment(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 116, in __init__
    self.set_dataset(dataset)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 205, in set_dataset
    self.data_puffs_all, self.data_wind_all = sim_analysis.load_plume(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 173, in load_plume
    data_puffs = pandas.read_pickle(puff_filename)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/pickle.py", line 185, in read_pickle
    with get_handle(
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/aaravsinha/plume/plumedata//puff_data_noisy6x5b5.pickle'
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x102dab220>, 't_val_min': 10.0, 'sim_steps_max': 2000, 'reset_offset_tmax': 30, 'dataset': 'noisy3x5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 4.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.3, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': True, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 6936, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
noisy3x5b5
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x102dab220>, 't_val_min': 10.0, 'sim_steps_max': 2000, 'reset_offset_tmax': 30, 'dataset': 'noisy3x5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 4.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.3, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': True, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 6936, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
noisy3x5b5
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
