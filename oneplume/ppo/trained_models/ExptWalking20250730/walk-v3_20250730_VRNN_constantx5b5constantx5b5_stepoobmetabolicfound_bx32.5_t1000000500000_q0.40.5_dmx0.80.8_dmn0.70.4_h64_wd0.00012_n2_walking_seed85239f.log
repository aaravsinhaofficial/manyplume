CUDA: False
Namespace(algo='ppo', lr=0.0003, eps=1e-05, alpha=0.99, gamma=0.99, use_gae=True, gae_lambda=0.95, entropy_coef=0.005, value_loss_coef=0.5, max_grad_norm=0.5, seed=8523, cuda_deterministic=False, num_processes=2, num_steps=2048, ppo_epoch=10, num_mini_batch=2, clip_param=0.2, log_interval=1, save_interval=100, no_cuda=False, use_proper_time_limits=False, recurrent_policy=True, use_linear_lr_decay=True, env_name='plume', log_dir='/tmp/gym/', save_dir='./trained_models/ExptWalking20250730/', dynamic=False, eval_type='fixed', eval_episodes=20, eval_interval=None, weight_decay=0.00012, rnn_type='VRNN', hidden_size=64, betadist=False, stacking=0, masking=None, stride=1, dataset=['constantx5b5', 'constantx5b5'], num_env_steps=[1000000, 500000], qvar=[0.4, 0.5], birthx=[3.0, 2.5], diff_max=[0.8, 0.8], diff_min=[0.7, 0.4], birthx_max=1.0, dryrun=False, curriculum=False, turnx=1.0, movex=1.0, auto_movex=False, auto_reward=False, loc_algo='uniform', time_algo='uniform', env_dt=0.04, outsuffix='walk-v3_20250730_VRNN_constantx5b5constantx5b5_stepoobmetabolicfound_bx32.5_t1000000500000_q0.40.5_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed85239f', walking=True, radiusx=1.0, diffusion_min=1.0, diffusion_max=1.0, r_shaping=['step', 'oob', 'metabolic', 'found'], wind_rel=True, action_feedback=False, squash_action=True, flipping=True, odor_scaling=True, stray_max=2.0, test_episodes=50, viz_episodes=10, model_fname='', obs_noise=0.0, act_noise=0.0, cuda=False)
PPO Args ---> Namespace(algo='ppo', lr=0.0003, eps=1e-05, alpha=0.99, gamma=0.99, use_gae=True, gae_lambda=0.95, entropy_coef=0.005, value_loss_coef=0.5, max_grad_norm=0.5, seed=8523, cuda_deterministic=False, num_processes=2, num_steps=2048, ppo_epoch=10, num_mini_batch=2, clip_param=0.2, log_interval=1, save_interval=100, no_cuda=False, use_proper_time_limits=False, recurrent_policy=True, use_linear_lr_decay=True, env_name='plume', log_dir='/tmp/gym/', save_dir='./trained_models/ExptWalking20250730/', dynamic=False, eval_type='fixed', eval_episodes=20, eval_interval=None, weight_decay=0.00012, rnn_type='VRNN', hidden_size=64, betadist=False, stacking=0, masking=None, stride=1, dataset=['constantx5b5', 'constantx5b5'], num_env_steps=[1000000, 500000], qvar=[0.4, 0.5], birthx=[3.0, 2.5], diff_max=[0.8, 0.8], diff_min=[0.7, 0.4], birthx_max=1.0, dryrun=False, curriculum=False, turnx=1.0, movex=1.0, auto_movex=False, auto_reward=False, loc_algo='uniform', time_algo='uniform', env_dt=0.04, outsuffix='walk-v3_20250730_VRNN_constantx5b5constantx5b5_stepoobmetabolicfound_bx32.5_t1000000500000_q0.40.5_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed85239f', walking=True, radiusx=1.0, diffusion_min=1.0, diffusion_max=1.0, r_shaping=['step', 'oob', 'metabolic', 'found'], wind_rel=True, action_feedback=False, squash_action=True, flipping=True, odor_scaling=True, stray_max=2.0, test_episodes=50, viz_episodes=10, model_fname='', obs_noise=0.0, act_noise=0.0, cuda=False)
Using Precomputed Plume...
Using Precomputed Plume...
2025-07-30 22:57:34.762 python[30473:55171310] +[NSXPCSharedListener endpointForReply:withListenerName:replyErrorCode:]: an error occurred while attempting to obtain endpoint for listener 'ClientCallsAuxiliary': Connection invalid
2025-07-30 22:57:34.762 python[30474:55171312] +[NSXPCSharedListener endpointForReply:withListenerName:replyErrorCode:]: an error occurred while attempting to obtain endpoint for listener 'ClientCallsAuxiliary': Connection invalid
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x155cbcdc0>, 't_val_min': 10.0, 'sim_steps_max': 1200, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 3.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.4, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.7, 'r_shaping': ['step', 'oob', 'metabolic', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': True, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 8523, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'found']
Using MLPBase
hidden_size 64
Using VanillaRNN
Saved ./trained_models/ExptWalking20250730//plume_walk-v3_20250730_VRNN_constantx5b5constantx5b5_stepoobmetabolicfound_bx32.5_t1000000500000_q0.40.5_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed85239f.pt.start
Stage: 0/2 - constantx5b5 b3.0 q0.4 n1000000
Saved ./trained_models/ExptWalking20250730/plume_walk-v3_20250730_VRNN_constantx5b5constantx5b5_stepoobmetabolicfound_bx32.5_t1000000500000_q0.40.5_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed85239f.pt
Update 0/244, T 4096, FPS 249, 24-training-episode: mean/median 12.8/-3.6, min/max -8.7/99.4
Update 1/244, T 8192, FPS 248, 50-training-episode: mean/median 12.4/-3.6, min/max -8.7/99.9
Update 2/244, T 12288, FPS 242, 50-training-episode: mean/median 4.8/-3.3, min/max -7.8/99.9
Update 3/244, T 16384, FPS 243, 50-training-episode: mean/median -1.2/-3.1, min/max -6.3/99.9
Update 4/244, T 20480, FPS 241, 50-training-episode: mean/median -3.2/-3.2, min/max -7.0/7.6
Update 5/244, T 24576, FPS 240, 50-training-episode: mean/median -2.9/-2.9, min/max -7.2/7.6
Update 6/244, T 28672, FPS 240, 50-training-episode: mean/median -3.2/-3.1, min/max -7.2/-1.5
Update 7/244, T 32768, FPS 240, 50-training-episode: mean/median -0.8/-2.7, min/max -4.4/98.0
Update 8/244, T 36864, FPS 240, 50-training-episode: mean/median -1.0/-2.9, min/max -4.6/98.0
Update 9/244, T 40960, FPS 241, 50-training-episode: mean/median -3.1/-2.9, min/max -5.3/-1.6
Update 10/244, T 45056, FPS 241, 50-training-episode: mean/median -3.1/-3.0, min/max -4.7/-1.7
Update 11/244, T 49152, FPS 240, 50-training-episode: mean/median -2.9/-2.8, min/max -4.8/-1.5
Update 12/244, T 53248, FPS 238, 50-training-episode: mean/median -2.8/-3.1, min/max -4.6/7.4
Update 13/244, T 57344, FPS 238, 50-training-episode: mean/median -3.0/-3.0, min/max -4.5/-1.8
Update 14/244, T 61440, FPS 238, 50-training-episode: mean/median -3.0/-2.9, min/max -5.4/-1.6
Update 15/244, T 65536, FPS 238, 50-training-episode: mean/median -3.2/-3.1, min/max -5.1/-1.6
Update 16/244, T 69632, FPS 238, 50-training-episode: mean/median -3.1/-2.9, min/max -5.1/-1.6
Update 17/244, T 73728, FPS 238, 50-training-episode: mean/median -2.9/-2.9, min/max -4.5/-1.7
Update 18/244, T 77824, FPS 237, 50-training-episode: mean/median -2.7/-2.9, min/max -5.0/6.8
Update 19/244, T 81920, FPS 237, 50-training-episode: mean/median -2.6/-2.7, min/max -4.9/6.8
Update 20/244, T 86016, FPS 237, 50-training-episode: mean/median -3.0/-2.9, min/max -4.8/-1.6
Update 21/244, T 90112, FPS 236, 50-training-episode: mean/median -2.8/-2.8, min/max -4.7/-1.9
Update 22/244, T 94208, FPS 236, 50-training-episode: mean/median -2.8/-2.7, min/max -4.4/-1.5
Update 23/244, T 98304, FPS 236, 50-training-episode: mean/median -2.8/-2.6, min/max -5.2/-1.6
Update 24/244, T 102400, FPS 236, 50-training-episode: mean/median -2.8/-2.6, min/max -4.7/-1.7
Update 25/244, T 106496, FPS 236, 50-training-episode: mean/median -2.9/-2.8, min/max -4.9/-1.4
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x1034cb220>, 't_val_min': 10.0, 'sim_steps_max': 1200, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 3.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.4, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.7, 'r_shaping': ['step', 'oob', 'metabolic', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': True, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 8523, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'found']
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x1034cb220>, 't_val_min': 10.0, 'sim_steps_max': 1200, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 3.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.4, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.7, 'r_shaping': ['step', 'oob', 'metabolic', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': True, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 8523, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'found']
