CUDA: False
Namespace(algo='ppo', lr=0.0003, eps=1e-05, alpha=0.99, gamma=0.99, use_gae=True, gae_lambda=0.95, entropy_coef=0.005, value_loss_coef=0.5, max_grad_norm=0.5, seed=8642, cuda_deterministic=False, num_processes=2, num_steps=2048, ppo_epoch=10, num_mini_batch=2, clip_param=0.2, log_interval=1, save_interval=100, no_cuda=False, use_proper_time_limits=False, recurrent_policy=True, use_linear_lr_decay=True, env_name='plume', log_dir='/tmp/gym/', save_dir='./trained_models/ExptWalking20250730/', dynamic=False, eval_type='fixed', eval_episodes=20, eval_interval=None, weight_decay=0.00012, rnn_type='VRNN', hidden_size=64, betadist=False, stacking=0, masking=None, stride=1, dataset=['constantx5b5', 'noisy3x5b5'], num_env_steps=[1000000, 200000], qvar=[0.4, 0.5], birthx=[3.0, 4.0], diff_max=[0.8, 0.8], diff_min=[0.7, 0.4], birthx_max=1.0, dryrun=False, curriculum=False, turnx=1.0, movex=1.0, auto_movex=False, auto_reward=False, loc_algo='uniform', time_algo='uniform', env_dt=0.04, outsuffix='walk-v3_20250730_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.40.5_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed864272', walking=True, radiusx=1.0, diffusion_min=1.0, diffusion_max=1.0, r_shaping=['step', 'oob', 'metabolic', 'turn', 'found'], wind_rel=True, action_feedback=False, squash_action=True, flipping=True, odor_scaling=True, stray_max=2.0, test_episodes=50, viz_episodes=10, model_fname='', obs_noise=0.0, act_noise=0.0, cuda=False)
PPO Args ---> Namespace(algo='ppo', lr=0.0003, eps=1e-05, alpha=0.99, gamma=0.99, use_gae=True, gae_lambda=0.95, entropy_coef=0.005, value_loss_coef=0.5, max_grad_norm=0.5, seed=8642, cuda_deterministic=False, num_processes=2, num_steps=2048, ppo_epoch=10, num_mini_batch=2, clip_param=0.2, log_interval=1, save_interval=100, no_cuda=False, use_proper_time_limits=False, recurrent_policy=True, use_linear_lr_decay=True, env_name='plume', log_dir='/tmp/gym/', save_dir='./trained_models/ExptWalking20250730/', dynamic=False, eval_type='fixed', eval_episodes=20, eval_interval=None, weight_decay=0.00012, rnn_type='VRNN', hidden_size=64, betadist=False, stacking=0, masking=None, stride=1, dataset=['constantx5b5', 'noisy3x5b5'], num_env_steps=[1000000, 200000], qvar=[0.4, 0.5], birthx=[3.0, 4.0], diff_max=[0.8, 0.8], diff_min=[0.7, 0.4], birthx_max=1.0, dryrun=False, curriculum=False, turnx=1.0, movex=1.0, auto_movex=False, auto_reward=False, loc_algo='uniform', time_algo='uniform', env_dt=0.04, outsuffix='walk-v3_20250730_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.40.5_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed864272', walking=True, radiusx=1.0, diffusion_min=1.0, diffusion_max=1.0, r_shaping=['step', 'oob', 'metabolic', 'turn', 'found'], wind_rel=True, action_feedback=False, squash_action=True, flipping=True, odor_scaling=True, stray_max=2.0, test_episodes=50, viz_episodes=10, model_fname='', obs_noise=0.0, act_noise=0.0, cuda=False)
Using Precomputed Plume...
Using Precomputed Plume...
2025-07-30 23:22:28.121 python[32225:55200062] +[NSXPCSharedListener endpointForReply:withListenerName:replyErrorCode:]: an error occurred while attempting to obtain endpoint for listener 'ClientCallsAuxiliary': Connection invalid
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x17b6a1cd0>, 't_val_min': 10.0, 'sim_steps_max': 2050, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 3.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.4, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.7, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': True, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 8642, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
Using MLPBase
hidden_size 64
Using VanillaRNN
Saved ./trained_models/ExptWalking20250730//plume_walk-v3_20250730_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.40.5_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed864272.pt.start
Stage: 0/2 - constantx5b5 b3.0 q0.4 n1000000
Saved ./trained_models/ExptWalking20250730/plume_walk-v3_20250730_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.40.5_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed864272.pt
Update 0/244, T 4096, FPS 165, 27-training-episode: mean/median -7.5/-6.9, min/max -18.6/-2.3
Update 1/244, T 8192, FPS 166, 50-training-episode: mean/median 1.3/-5.7, min/max -18.6/98.4
Update 2/244, T 12288, FPS 162, 50-training-episode: mean/median -2.6/-5.9, min/max -22.0/97.3
Update 3/244, T 16384, FPS 163, 50-training-episode: mean/median -2.5/-6.5, min/max -12.7/97.7
Update 4/244, T 20480, FPS 162, 50-training-episode: mean/median 4.1/-5.0, min/max -14.1/98.7
Update 5/244, T 24576, FPS 161, 50-training-episode: mean/median -2.0/-5.4, min/max -14.1/92.7
Update 6/244, T 28672, FPS 160, 50-training-episode: mean/median 2.3/-4.9, min/max -10.4/98.3
Update 7/244, T 32768, FPS 159, 50-training-episode: mean/median 2.8/-4.5, min/max -11.7/98.6
Update 8/244, T 36864, FPS 158, 50-training-episode: mean/median 6.9/-4.4, min/max -11.9/98.4
Update 9/244, T 40960, FPS 158, 50-training-episode: mean/median 7.4/-3.8, min/max -11.1/98.1
Update 10/244, T 45056, FPS 158, 50-training-episode: mean/median 1.2/-4.5, min/max -13.1/97.3
Update 11/244, T 49152, FPS 158, 50-training-episode: mean/median 0.6/-4.7, min/max -11.0/96.8
Update 12/244, T 53248, FPS 158, 50-training-episode: mean/median 4.6/-4.7, min/max -10.9/98.5
Update 13/244, T 57344, FPS 157, 50-training-episode: mean/median 1.3/-4.0, min/max -12.7/96.6
Update 14/244, T 61440, FPS 157, 50-training-episode: mean/median 4.9/-4.4, min/max -10.7/97.2
Update 15/244, T 65536, FPS 157, 50-training-episode: mean/median 2.8/-4.9, min/max -11.8/97.3
Update 16/244, T 69632, FPS 157, 50-training-episode: mean/median 9.0/-3.7, min/max -11.3/98.7
Update 17/244, T 73728, FPS 156, 50-training-episode: mean/median 13.4/-3.4, min/max -11.4/98.8
Update 18/244, T 77824, FPS 156, 50-training-episode: mean/median 15.3/-3.9, min/max -11.4/98.7
Update 19/244, T 81920, FPS 156, 50-training-episode: mean/median 31.0/-3.6, min/max -9.1/99.1
Update 20/244, T 86016, FPS 157, 50-training-episode: mean/median 33.0/-3.2, min/max -10.3/107.7
Update 21/244, T 90112, FPS 158, 50-training-episode: mean/median 37.4/-2.8, min/max -10.3/99.0
Update 22/244, T 94208, FPS 158, 50-training-episode: mean/median 27.9/-2.7, min/max -8.8/98.3
Update 23/244, T 98304, FPS 158, 50-training-episode: mean/median 31.6/-3.1, min/max -8.8/98.8
Update 24/244, T 102400, FPS 158, 50-training-episode: mean/median 37.4/-3.3, min/max -8.9/98.8
Update 25/244, T 106496, FPS 158, 50-training-episode: mean/median 43.1/-1.9, min/max -9.8/98.5
Update 26/244, T 110592, FPS 158, 50-training-episode: mean/median 45.3/49.5, min/max -10.1/98.5
Update 27/244, T 114688, FPS 158, 50-training-episode: mean/median 32.6/-3.0, min/max -11.0/98.2
Update 28/244, T 118784, FPS 158, 50-training-episode: mean/median 33.5/-2.7, min/max -9.8/98.2
Update 29/244, T 122880, FPS 157, 50-training-episode: mean/median 29.1/-3.5, min/max -9.7/98.4
Update 30/244, T 126976, FPS 157, 50-training-episode: mean/median 36.8/-3.1, min/max -9.9/98.4
Update 31/244, T 131072, FPS 156, 50-training-episode: mean/median 25.1/-4.1, min/max -9.7/98.0
Update 32/244, T 135168, FPS 156, 50-training-episode: mean/median 35.4/-2.9, min/max -11.8/98.9
Update 33/244, T 139264, FPS 155, 50-training-episode: mean/median 45.3/44.8, min/max -12.0/98.9
Update 34/244, T 143360, FPS 155, 50-training-episode: mean/median 55.5/94.0, min/max -8.3/98.8
Update 35/244, T 147456, FPS 154, 50-training-episode: mean/median 35.0/-3.2, min/max -10.3/98.2
Update 36/244, T 151552, FPS 154, 50-training-episode: mean/median 34.5/-3.0, min/max -13.1/98.3
Update 37/244, T 155648, FPS 153, 50-training-episode: mean/median 45.7/47.6, min/max -13.1/98.3
Update 38/244, T 159744, FPS 152, 50-training-episode: mean/median 52.3/95.0, min/max -11.0/107.0
Update 39/244, T 163840, FPS 152, 50-training-episode: mean/median 55.9/94.8, min/max -10.4/104.4
Update 40/244, T 167936, FPS 151, 50-training-episode: mean/median 33.3/-2.9, min/max -10.4/104.4
Update 41/244, T 172032, FPS 151, 50-training-episode: mean/median 49.4/93.2, min/max -10.4/102.7
Update 42/244, T 176128, FPS 150, 50-training-episode: mean/median 73.7/95.3, min/max -9.6/102.7
Update 43/244, T 180224, FPS 150, 50-training-episode: mean/median 65.7/95.8, min/max -8.8/98.5
Update 44/244, T 184320, FPS 150, 50-training-episode: mean/median 53.7/93.7, min/max -8.5/98.4
Update 45/244, T 188416, FPS 150, 50-training-episode: mean/median 41.9/-2.6, min/max -8.1/99.4
Update 46/244, T 192512, FPS 149, 50-training-episode: mean/median 53.8/94.1, min/max -8.1/102.2
Update 47/244, T 196608, FPS 149, 50-training-episode: mean/median 59.7/95.0, min/max -9.9/104.9
Update 48/244, T 200704, FPS 148, 50-training-episode: mean/median 59.9/95.5, min/max -14.3/107.5
Update 49/244, T 204800, FPS 148, 50-training-episode: mean/median 58.2/95.7, min/max -14.3/107.5
Update 50/244, T 208896, FPS 147, 50-training-episode: mean/median 52.1/95.3, min/max -7.5/98.1
Update 51/244, T 212992, FPS 147, 50-training-episode: mean/median 47.9/94.3, min/max -10.6/98.8
Update 52/244, T 217088, FPS 146, 50-training-episode: mean/median 45.5/46.0, min/max -10.6/98.8
Update 53/244, T 221184, FPS 146, 50-training-episode: mean/median 39.4/-2.7, min/max -11.4/98.5
Update 54/244, T 225280, FPS 145, 50-training-episode: mean/median 40.1/-2.6, min/max -9.5/108.3
Update 55/244, T 229376, FPS 145, 50-training-episode: mean/median 51.9/94.7, min/max -10.5/98.8
Update 56/244, T 233472, FPS 144, 50-training-episode: mean/median 37.5/-3.1, min/max -10.5/106.6
Update 57/244, T 237568, FPS 144, 50-training-episode: mean/median 29.9/-2.9, min/max -11.2/106.6
Update 58/244, T 241664, FPS 144, 50-training-episode: mean/median 31.2/-3.5, min/max -10.9/99.2
Update 59/244, T 245760, FPS 144, 50-training-episode: mean/median 31.9/-2.3, min/max -10.9/99.0
Update 60/244, T 249856, FPS 143, 50-training-episode: mean/median 42.2/2.9, min/max -9.4/98.7
Update 61/244, T 253952, FPS 143, 50-training-episode: mean/median 39.8/-2.3, min/max -10.0/98.7
Update 62/244, T 258048, FPS 142, 50-training-episode: mean/median 27.7/-3.2, min/max -10.1/107.2
Update 63/244, T 262144, FPS 142, 50-training-episode: mean/median 33.0/-3.2, min/max -12.1/98.6
Update 64/244, T 266240, FPS 142, 50-training-episode: mean/median 45.6/46.6, min/max -10.5/98.6
Update 65/244, T 270336, FPS 142, 50-training-episode: mean/median 57.7/95.0, min/max -8.4/98.5
Update 66/244, T 274432, FPS 141, 50-training-episode: mean/median 44.0/3.2, min/max -10.2/98.9
Update 67/244, T 278528, FPS 141, 50-training-episode: mean/median 51.7/95.0, min/max -11.8/98.2
Update 68/244, T 282624, FPS 141, 50-training-episode: mean/median 60.2/95.1, min/max -7.8/107.1
Update 69/244, T 286720, FPS 141, 50-training-episode: mean/median 60.2/95.3, min/max -8.5/99.1
Update 70/244, T 290816, FPS 141, 50-training-episode: mean/median 68.1/96.0, min/max -8.5/99.4
Update 71/244, T 294912, FPS 141, 50-training-episode: mean/median 51.7/95.5, min/max -9.6/98.9
Update 72/244, T 299008, FPS 141, 50-training-episode: mean/median 49.7/93.9, min/max -8.9/98.9
Update 73/244, T 303104, FPS 141, 50-training-episode: mean/median 43.5/-2.7, min/max -8.3/98.7
Update 74/244, T 307200, FPS 141, 50-training-episode: mean/median 48.0/92.3, min/max -7.3/99.3
Update 75/244, T 311296, FPS 141, 50-training-episode: mean/median 55.5/93.9, min/max -8.1/98.6
Update 76/244, T 315392, FPS 141, 50-training-episode: mean/median 44.1/-2.0, min/max -7.6/99.3
Update 77/244, T 319488, FPS 141, 50-training-episode: mean/median 54.0/95.7, min/max -10.7/99.3
Update 78/244, T 323584, FPS 141, 50-training-episode: mean/median 62.0/95.5, min/max -10.7/106.9
Update 79/244, T 327680, FPS 141, 50-training-episode: mean/median 60.2/95.2, min/max -7.9/107.4
Update 80/244, T 331776, FPS 141, 50-training-episode: mean/median 54.5/95.3, min/max -7.0/99.1
Update 81/244, T 335872, FPS 140, 50-training-episode: mean/median 56.5/95.9, min/max -8.8/107.2
Update 82/244, T 339968, FPS 140, 50-training-episode: mean/median 58.7/95.7, min/max -8.8/108.6
Update 83/244, T 344064, FPS 140, 50-training-episode: mean/median 48.7/94.0, min/max -9.2/108.6
Update 84/244, T 348160, FPS 140, 50-training-episode: mean/median 56.5/95.2, min/max -8.9/108.5
Update 85/244, T 352256, FPS 140, 50-training-episode: mean/median 65.0/96.0, min/max -9.2/108.5
Update 86/244, T 356352, FPS 140, 50-training-episode: mean/median 60.6/96.0, min/max -9.2/99.0
Update 87/244, T 360448, FPS 141, 50-training-episode: mean/median 52.0/95.5, min/max -8.0/99.0
Update 88/244, T 364544, FPS 140, 50-training-episode: mean/median 54.2/95.6, min/max -9.1/99.1
Update 89/244, T 368640, FPS 140, 50-training-episode: mean/median 64.5/96.5, min/max -9.1/99.2
Update 90/244, T 372736, FPS 140, 50-training-episode: mean/median 56.4/95.7, min/max -7.5/99.3
Update 91/244, T 376832, FPS 140, 50-training-episode: mean/median 58.5/95.4, min/max -6.2/98.7
Update 92/244, T 380928, FPS 140, 50-training-episode: mean/median 46.4/46.0, min/max -8.1/99.6
Update 93/244, T 385024, FPS 140, 50-training-episode: mean/median 54.3/95.6, min/max -8.3/100.0
Update 94/244, T 389120, FPS 141, 50-training-episode: mean/median 50.3/94.9, min/max -9.6/100.0
Update 95/244, T 393216, FPS 141, 50-training-episode: mean/median 50.5/94.9, min/max -8.6/99.2
Update 96/244, T 397312, FPS 141, 50-training-episode: mean/median 64.8/96.1, min/max -6.3/98.6
Update 97/244, T 401408, FPS 141, 50-training-episode: mean/median 66.6/95.9, min/max -7.9/99.3
Update 98/244, T 405504, FPS 141, 50-training-episode: mean/median 60.6/96.0, min/max -9.5/108.2
Update 99/244, T 409600, FPS 141, 50-training-episode: mean/median 54.1/95.3, min/max -9.1/99.4
Saved ./trained_models/ExptWalking20250730/plume_walk-v3_20250730_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.40.5_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed864272.pt
Saved ./trained_models/ExptWalking20250730/plume_walk-v3_20250730_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.40.5_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed864272.pt.best
Update 100/244, T 413696, FPS 141, 50-training-episode: mean/median 52.5/95.8, min/max -8.9/99.4
Update 101/244, T 417792, FPS 141, 50-training-episode: mean/median 42.0/-2.4, min/max -9.2/108.7
Update 102/244, T 421888, FPS 141, 50-training-episode: mean/median 46.8/50.6, min/max -8.7/107.8
Update 103/244, T 425984, FPS 141, 50-training-episode: mean/median 54.5/95.8, min/max -6.9/99.2
Update 104/244, T 430080, FPS 141, 50-training-episode: mean/median 64.6/96.4, min/max -6.7/99.2
Update 105/244, T 434176, FPS 141, 50-training-episode: mean/median 54.5/94.9, min/max -6.9/108.9
Update 106/244, T 438272, FPS 141, 50-training-episode: mean/median 50.5/94.1, min/max -7.1/108.9
Update 107/244, T 442368, FPS 141, 50-training-episode: mean/median 50.1/95.0, min/max -8.1/99.5
Update 108/244, T 446464, FPS 141, 50-training-episode: mean/median 48.3/93.8, min/max -10.0/99.2
Update 109/244, T 450560, FPS 141, 50-training-episode: mean/median 47.9/93.0, min/max -10.0/99.1
Update 110/244, T 454656, FPS 141, 50-training-episode: mean/median 66.3/95.8, min/max -6.1/99.2
Update 111/244, T 458752, FPS 141, 50-training-episode: mean/median 68.5/96.4, min/max -7.4/99.6
Update 112/244, T 462848, FPS 141, 50-training-episode: mean/median 72.3/95.7, min/max -6.1/99.1
Update 113/244, T 466944, FPS 141, 50-training-episode: mean/median 64.7/95.7, min/max -8.1/99.1
Update 114/244, T 471040, FPS 141, 50-training-episode: mean/median 60.6/95.6, min/max -10.4/99.0
Update 115/244, T 475136, FPS 141, 50-training-episode: mean/median 75.0/95.9, min/max -4.9/108.1
Update 116/244, T 479232, FPS 141, 50-training-episode: mean/median 79.0/95.5, min/max -4.7/108.1
Update 117/244, T 483328, FPS 141, 50-training-episode: mean/median 70.6/95.7, min/max -6.7/98.6
Update 118/244, T 487424, FPS 141, 50-training-episode: mean/median 64.2/95.8, min/max -10.9/99.0
Update 119/244, T 491520, FPS 141, 50-training-episode: mean/median 66.4/95.8, min/max -10.9/98.7
Update 120/244, T 495616, FPS 141, 50-training-episode: mean/median 52.3/94.8, min/max -8.1/98.7
Update 121/244, T 499712, FPS 141, 50-training-episode: mean/median 50.3/94.4, min/max -8.4/108.6
Update 122/244, T 503808, FPS 141, 50-training-episode: mean/median 58.2/95.1, min/max -8.4/99.1
Update 123/244, T 507904, FPS 141, 50-training-episode: mean/median 60.4/95.8, min/max -8.4/108.2
Update 124/244, T 512000, FPS 141, 50-training-episode: mean/median 54.4/94.7, min/max -7.0/108.2
Update 125/244, T 516096, FPS 141, 50-training-episode: mean/median 60.2/96.0, min/max -7.9/99.6
Update 126/244, T 520192, FPS 141, 50-training-episode: mean/median 51.9/94.8, min/max -7.9/98.4
Update 127/244, T 524288, FPS 141, 50-training-episode: mean/median 66.0/95.4, min/max -7.5/98.5
Update 128/244, T 528384, FPS 141, 50-training-episode: mean/median 66.4/95.5, min/max -9.3/99.3
Update 129/244, T 532480, FPS 141, 50-training-episode: mean/median 70.7/96.4, min/max -8.0/99.3
Update 130/244, T 536576, FPS 141, 50-training-episode: mean/median 68.9/95.7, min/max -7.2/108.0
Update 131/244, T 540672, FPS 141, 50-training-episode: mean/median 64.5/95.6, min/max -9.6/108.0
Update 132/244, T 544768, FPS 142, 50-training-episode: mean/median 58.3/95.0, min/max -10.6/108.3
Update 133/244, T 548864, FPS 142, 50-training-episode: mean/median 68.3/95.7, min/max -8.1/98.5
Update 134/244, T 552960, FPS 142, 50-training-episode: mean/median 66.2/95.5, min/max -7.6/98.4
Update 135/244, T 557056, FPS 142, 50-training-episode: mean/median 70.0/95.6, min/max -8.5/98.4
Update 136/244, T 561152, FPS 142, 50-training-episode: mean/median 76.5/96.3, min/max -6.8/98.8
Update 137/244, T 565248, FPS 142, 50-training-episode: mean/median 74.7/96.8, min/max -6.6/99.2
Update 138/244, T 569344, FPS 142, 50-training-episode: mean/median 58.5/95.9, min/max -8.7/98.9
Update 139/244, T 573440, FPS 142, 50-training-episode: mean/median 62.4/96.0, min/max -9.2/98.9
Update 140/244, T 577536, FPS 142, 50-training-episode: mean/median 70.2/95.7, min/max -9.2/98.4
Update 141/244, T 581632, FPS 142, 50-training-episode: mean/median 70.7/96.6, min/max -7.9/99.0
Update 142/244, T 585728, FPS 142, 50-training-episode: mean/median 70.6/96.0, min/max -6.6/107.7
Update 143/244, T 589824, FPS 142, 50-training-episode: mean/median 51.7/94.1, min/max -9.1/99.3
Update 144/244, T 593920, FPS 142, 50-training-episode: mean/median 70.5/96.3, min/max -7.8/106.6
Update 145/244, T 598016, FPS 142, 50-training-episode: mean/median 70.9/96.0, min/max -5.4/109.2
Update 146/244, T 602112, FPS 142, 50-training-episode: mean/median 74.7/96.2, min/max -5.3/106.4
Update 147/244, T 606208, FPS 142, 50-training-episode: mean/median 74.4/95.9, min/max -4.0/98.9
Update 148/244, T 610304, FPS 142, 50-training-episode: mean/median 78.5/96.2, min/max -7.7/99.4
Update 149/244, T 614400, FPS 142, 50-training-episode: mean/median 74.7/96.4, min/max -7.7/108.0
Update 150/244, T 618496, FPS 142, 50-training-episode: mean/median 78.7/96.3, min/max -4.4/99.7
Update 151/244, T 622592, FPS 142, 50-training-episode: mean/median 60.4/95.6, min/max -7.4/98.8
Update 152/244, T 626688, FPS 142, 50-training-episode: mean/median 62.5/96.2, min/max -7.5/98.8
Update 153/244, T 630784, FPS 142, 50-training-episode: mean/median 74.5/96.3, min/max -7.5/99.0
Update 154/244, T 634880, FPS 142, 50-training-episode: mean/median 68.3/95.6, min/max -8.2/99.7
Update 155/244, T 638976, FPS 142, 50-training-episode: mean/median 54.6/95.5, min/max -9.6/99.7
Update 156/244, T 643072, FPS 142, 50-training-episode: mean/median 60.6/95.8, min/max -8.7/98.6
Update 157/244, T 647168, FPS 142, 50-training-episode: mean/median 66.1/95.8, min/max -7.9/99.3
Update 158/244, T 651264, FPS 142, 50-training-episode: mean/median 50.1/95.1, min/max -7.9/98.6
Update 159/244, T 655360, FPS 142, 50-training-episode: mean/median 52.2/95.3, min/max -9.0/99.3
Update 160/244, T 659456, FPS 142, 50-training-episode: mean/median 40.5/-2.4, min/max -8.5/107.9
Update 161/244, T 663552, FPS 142, 50-training-episode: mean/median 46.9/51.1, min/max -7.6/107.9
Update 162/244, T 667648, FPS 142, 50-training-episode: mean/median 44.0/3.2, min/max -10.1/98.9
Update 163/244, T 671744, FPS 142, 50-training-episode: mean/median 44.1/2.9, min/max -9.5/98.9
Update 164/244, T 675840, FPS 142, 50-training-episode: mean/median 54.7/96.2, min/max -7.1/98.5
Update 165/244, T 679936, FPS 142, 50-training-episode: mean/median 48.4/94.4, min/max -9.2/99.5
Update 166/244, T 684032, FPS 142, 50-training-episode: mean/median 58.7/96.3, min/max -9.6/99.5
Update 167/244, T 688128, FPS 142, 50-training-episode: mean/median 52.4/95.9, min/max -11.4/99.5
Update 168/244, T 692224, FPS 142, 50-training-episode: mean/median 40.1/-2.2, min/max -9.7/99.5
Update 169/244, T 696320, FPS 142, 50-training-episode: mean/median 55.8/95.8, min/max -11.1/99.5
Update 170/244, T 700416, FPS 142, 50-training-episode: mean/median 49.7/95.1, min/max -10.7/98.9
Update 171/244, T 704512, FPS 142, 50-training-episode: mean/median 50.4/94.5, min/max -9.9/107.1
Update 172/244, T 708608, FPS 142, 50-training-episode: mean/median 56.1/95.1, min/max -9.0/99.2
Update 173/244, T 712704, FPS 142, 50-training-episode: mean/median 66.4/96.1, min/max -8.8/99.3
Update 174/244, T 716800, FPS 142, 50-training-episode: mean/median 70.7/96.1, min/max -8.8/107.0
Update 175/244, T 720896, FPS 142, 50-training-episode: mean/median 68.6/96.1, min/max -9.4/105.5
Update 176/244, T 724992, FPS 142, 50-training-episode: mean/median 72.5/96.4, min/max -10.0/99.3
Update 177/244, T 729088, FPS 142, 50-training-episode: mean/median 71.1/96.7, min/max -10.0/108.8
Update 178/244, T 733184, FPS 142, 50-training-episode: mean/median 68.5/95.7, min/max -9.5/108.8
Update 179/244, T 737280, FPS 142, 50-training-episode: mean/median 66.3/95.9, min/max -9.5/99.2
Update 180/244, T 741376, FPS 142, 50-training-episode: mean/median 64.6/96.0, min/max -9.5/99.3
Update 181/244, T 745472, FPS 142, 50-training-episode: mean/median 60.8/95.8, min/max -7.8/108.2
Update 182/244, T 749568, FPS 142, 50-training-episode: mean/median 62.7/96.1, min/max -9.3/99.6
Update 183/244, T 753664, FPS 142, 50-training-episode: mean/median 58.6/94.9, min/max -5.0/99.5
Update 184/244, T 757760, FPS 142, 50-training-episode: mean/median 70.8/96.3, min/max -8.9/99.1
Update 185/244, T 761856, FPS 142, 50-training-episode: mean/median 58.2/95.4, min/max -11.6/99.5
Update 186/244, T 765952, FPS 142, 50-training-episode: mean/median 82.6/96.2, min/max -3.5/99.5
Update 187/244, T 770048, FPS 142, 50-training-episode: mean/median 70.6/95.9, min/max -6.2/99.4
Update 188/244, T 774144, FPS 142, 50-training-episode: mean/median 64.7/96.0, min/max -8.4/99.3
Update 189/244, T 778240, FPS 142, 50-training-episode: mean/median 68.1/95.8, min/max -18.0/99.2
Update 190/244, T 782336, FPS 142, 50-training-episode: mean/median 80.7/96.7, min/max -18.0/99.7
Update 191/244, T 786432, FPS 142, 50-training-episode: mean/median 76.7/96.4, min/max -10.2/99.7
Update 192/244, T 790528, FPS 142, 50-training-episode: mean/median 70.0/95.9, min/max -16.8/99.3
Update 193/244, T 794624, FPS 142, 50-training-episode: mean/median 68.8/96.2, min/max -9.9/106.9
Update 194/244, T 798720, FPS 142, 50-training-episode: mean/median 66.1/95.6, min/max -10.7/99.1
Update 195/244, T 802816, FPS 142, 50-training-episode: mean/median 86.4/96.4, min/max -10.7/99.2
Update 196/244, T 806912, FPS 142, 50-training-episode: mean/median 70.8/95.6, min/max -4.9/99.3
Update 197/244, T 811008, FPS 142, 50-training-episode: mean/median 69.1/96.4, min/max -7.6/99.6
Update 198/244, T 815104, FPS 142, 50-training-episode: mean/median 72.4/95.6, min/max -7.6/99.6
Update 199/244, T 819200, FPS 142, 50-training-episode: mean/median 76.6/96.5, min/max -7.3/99.5
Saved ./trained_models/ExptWalking20250730/plume_walk-v3_20250730_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.40.5_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed864272.pt
Saved ./trained_models/ExptWalking20250730/plume_walk-v3_20250730_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.40.5_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed864272.pt.best
Update 200/244, T 823296, FPS 142, 50-training-episode: mean/median 78.7/96.8, min/max -8.7/99.5
Update 201/244, T 827392, FPS 142, 50-training-episode: mean/median 78.8/96.3, min/max -8.3/108.0
Update 202/244, T 831488, FPS 142, 50-training-episode: mean/median 70.7/96.3, min/max -5.7/99.0
Update 203/244, T 835584, FPS 142, 50-training-episode: mean/median 78.6/96.3, min/max -9.0/99.7
Update 204/244, T 839680, FPS 142, 50-training-episode: mean/median 77.2/97.1, min/max -9.0/107.5
Update 205/244, T 843776, FPS 142, 50-training-episode: mean/median 70.5/96.6, min/max -9.7/99.6
Update 206/244, T 847872, FPS 142, 50-training-episode: mean/median 70.3/96.1, min/max -9.7/107.1
Update 207/244, T 851968, FPS 142, 50-training-episode: mean/median 84.8/96.9, min/max -8.8/108.2
Update 208/244, T 856064, FPS 142, 50-training-episode: mean/median 66.8/95.6, min/max -6.8/99.8
Update 209/244, T 860160, FPS 142, 50-training-episode: mean/median 72.4/96.5, min/max -7.4/99.0
Update 210/244, T 864256, FPS 142, 50-training-episode: mean/median 62.1/95.1, min/max -6.8/99.2
Update 211/244, T 868352, FPS 142, 50-training-episode: mean/median 66.4/95.4, min/max -10.3/106.3
Update 212/244, T 872448, FPS 142, 50-training-episode: mean/median 68.2/95.8, min/max -10.4/99.0
Update 213/244, T 876544, FPS 142, 50-training-episode: mean/median 66.0/96.2, min/max -10.4/98.9
Update 214/244, T 880640, FPS 142, 50-training-episode: mean/median 76.7/96.7, min/max -7.2/105.6
Update 215/244, T 884736, FPS 142, 50-training-episode: mean/median 80.9/97.0, min/max -6.8/99.5
Update 216/244, T 888832, FPS 142, 50-training-episode: mean/median 72.8/96.0, min/max -4.5/108.9
Update 217/244, T 892928, FPS 142, 50-training-episode: mean/median 62.7/96.0, min/max -9.3/108.9
Update 218/244, T 897024, FPS 142, 50-training-episode: mean/median 84.7/97.1, min/max -6.4/99.2
Update 219/244, T 901120, FPS 142, 50-training-episode: mean/median 80.6/95.7, min/max -6.0/99.5
Update 220/244, T 905216, FPS 142, 50-training-episode: mean/median 73.1/96.2, min/max -5.9/108.9
Update 221/244, T 909312, FPS 142, 50-training-episode: mean/median 70.7/96.0, min/max -6.6/98.8
Update 222/244, T 913408, FPS 142, 50-training-episode: mean/median 66.5/95.9, min/max -5.3/98.9
Update 223/244, T 917504, FPS 142, 50-training-episode: mean/median 72.8/95.8, min/max -4.7/108.1
Update 224/244, T 921600, FPS 142, 50-training-episode: mean/median 77.3/96.5, min/max -9.3/108.5
Update 225/244, T 925696, FPS 142, 50-training-episode: mean/median 72.9/96.4, min/max -4.9/105.8
Update 226/244, T 929792, FPS 142, 50-training-episode: mean/median 63.3/96.2, min/max -9.7/108.0
Update 227/244, T 933888, FPS 142, 50-training-episode: mean/median 71.5/96.5, min/max -4.9/108.8
Update 228/244, T 937984, FPS 142, 50-training-episode: mean/median 65.0/95.9, min/max -4.1/98.4
Update 229/244, T 942080, FPS 142, 50-training-episode: mean/median 62.7/96.0, min/max -5.1/98.5
Update 230/244, T 946176, FPS 142, 50-training-episode: mean/median 82.5/96.2, min/max -5.1/99.1
Update 231/244, T 950272, FPS 142, 50-training-episode: mean/median 74.4/95.9, min/max -8.3/99.5
Update 232/244, T 954368, FPS 142, 50-training-episode: mean/median 82.7/96.0, min/max -3.4/107.5
Update 233/244, T 958464, FPS 142, 50-training-episode: mean/median 76.4/96.2, min/max -9.1/107.5
Update 234/244, T 962560, FPS 142, 50-training-episode: mean/median 78.3/96.2, min/max -8.3/99.0
Update 235/244, T 966656, FPS 142, 50-training-episode: mean/median 78.6/96.0, min/max -4.9/108.5
Update 236/244, T 970752, FPS 142, 50-training-episode: mean/median 70.6/95.9, min/max -6.5/98.9
Update 237/244, T 974848, FPS 142, 50-training-episode: mean/median 68.6/96.0, min/max -17.7/105.2
Update 238/244, T 978944, FPS 142, 50-training-episode: mean/median 60.7/95.5, min/max -17.7/107.9
Update 239/244, T 983040, FPS 142, 50-training-episode: mean/median 76.7/96.3, min/max -4.7/98.3
Update 240/244, T 987136, FPS 142, 50-training-episode: mean/median 80.1/96.0, min/max -16.9/99.1
Update 241/244, T 991232, FPS 142, 50-training-episode: mean/median 72.5/96.3, min/max -11.4/99.4
Update 242/244, T 995328, FPS 142, 50-training-episode: mean/median 70.3/96.3, min/max -11.4/99.4
Saved ./trained_models/ExptWalking20250730/plume_walk-v3_20250730_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.40.5_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed864272.pt
Update 243/244, T 999424, FPS 142, 50-training-episode: mean/median 68.1/95.9, min/max -10.1/98.6
Stage: 1/2 - noisy3x5b5 b4.0 q0.5 n200000
Using Precomputed Plume...
Using Precomputed Plume...
2025-07-31 01:20:13.261 python[40034:55378954] +[NSXPCSharedListener endpointForReply:withListenerName:replyErrorCode:]: an error occurred while attempting to obtain endpoint for listener 'ClientCallsAuxiliary': Connection invalid
2025-07-31 01:20:13.261 python[40035:55378955] +[NSXPCSharedListener endpointForReply:withListenerName:replyErrorCode:]: an error occurred while attempting to obtain endpoint for listener 'ClientCallsAuxiliary': Connection invalid
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x1011fb220>, 't_val_min': 10.0, 'sim_steps_max': 2050, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 3.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.4, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.7, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': True, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 8642, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x1011fb220>, 't_val_min': 10.0, 'sim_steps_max': 2050, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 3.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.4, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.7, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': True, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 8642, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
Saved ./trained_models/ExptWalking20250730/plume_walk-v3_20250730_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.40.5_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed864272.pt
Update 0/48, T 4096, FPS 85, 50-training-episode: mean/median 4.6/-1.3, min/max -5.1/108.1
Update 1/48, T 8192, FPS 91, 50-training-episode: mean/median 2.0/-1.4, min/max -8.6/96.0
Update 2/48, T 12288, FPS 96, 50-training-episode: mean/median 0.3/-1.5, min/max -9.1/98.8
Update 3/48, T 16384, FPS 94, 50-training-episode: mean/median 0.0/-1.5, min/max -6.9/97.6
Update 4/48, T 20480, FPS 96, 50-training-episode: mean/median 4.1/-1.4, min/max -9.1/104.3
Update 5/48, T 24576, FPS 96, 50-training-episode: mean/median -2.1/-1.6, min/max -9.5/3.7
Update 6/48, T 28672, FPS 95, 50-training-episode: mean/median 2.5/-1.4, min/max -6.0/104.2
Update 7/48, T 32768, FPS 95, 50-training-episode: mean/median -2.2/-1.6, min/max -8.5/8.7
Update 8/48, T 36864, FPS 95, 50-training-episode: mean/median -0.2/-1.5, min/max -6.2/93.3
Update 9/48, T 40960, FPS 96, 50-training-episode: mean/median -1.6/-1.4, min/max -9.6/7.0
Update 10/48, T 45056, FPS 95, 50-training-episode: mean/median 1.2/-1.3, min/max -4.6/99.5
Update 11/48, T 49152, FPS 96, 50-training-episode: mean/median -1.9/-1.5, min/max -6.1/4.4
Update 12/48, T 53248, FPS 96, 50-training-episode: mean/median 0.2/-1.5, min/max -11.3/106.3
Update 13/48, T 57344, FPS 96, 50-training-episode: mean/median -1.8/-1.5, min/max -8.3/5.0
Update 14/48, T 61440, FPS 95, 50-training-episode: mean/median 4.6/-1.3, min/max -5.5/96.4
Update 15/48, T 65536, FPS 95, 50-training-episode: mean/median -1.9/-1.5, min/max -7.9/5.2
Update 16/48, T 69632, FPS 95, 50-training-episode: mean/median -1.3/-1.3, min/max -7.9/7.5
Update 17/48, T 73728, FPS 95, 50-training-episode: mean/median -0.1/-1.4, min/max -8.2/95.0
Update 18/48, T 77824, FPS 95, 50-training-episode: mean/median 2.4/-1.3, min/max -5.7/96.0
Update 19/48, T 81920, FPS 95, 50-training-episode: mean/median -1.6/-1.5, min/max -4.0/3.5
Update 20/48, T 86016, FPS 96, 50-training-episode: mean/median 0.1/-1.4, min/max -9.8/96.0
Update 21/48, T 90112, FPS 96, 50-training-episode: mean/median -0.1/-1.4, min/max -7.9/95.2
Update 22/48, T 94208, FPS 96, 50-training-episode: mean/median 2.4/-1.5, min/max -5.7/98.7
Update 23/48, T 98304, FPS 96, 50-training-episode: mean/median -1.6/-1.5, min/max -9.6/8.5
Update 24/48, T 102400, FPS 96, 50-training-episode: mean/median 2.3/-1.4, min/max -7.9/99.1
Update 25/48, T 106496, FPS 96, 50-training-episode: mean/median -2.0/-1.4, min/max -8.9/-0.8
Update 26/48, T 110592, FPS 96, 50-training-episode: mean/median -1.6/-1.4, min/max -6.7/5.7
Update 27/48, T 114688, FPS 96, 50-training-episode: mean/median -2.0/-1.4, min/max -11.2/8.6
Update 28/48, T 118784, FPS 96, 50-training-episode: mean/median -2.3/-1.6, min/max -7.9/7.9
Update 29/48, T 122880, FPS 96, 50-training-episode: mean/median -1.8/-1.4, min/max -5.8/4.2
Update 30/48, T 126976, FPS 96, 50-training-episode: mean/median -1.7/-1.4, min/max -5.4/5.9
Update 31/48, T 131072, FPS 96, 50-training-episode: mean/median -1.9/-1.5, min/max -6.5/8.7
Update 32/48, T 135168, FPS 96, 50-training-episode: mean/median -2.0/-1.5, min/max -8.1/8.4
Update 33/48, T 139264, FPS 96, 50-training-episode: mean/median -2.2/-1.6, min/max -7.6/6.2
Update 34/48, T 143360, FPS 96, 50-training-episode: mean/median -2.1/-1.5, min/max -7.8/-0.7
Update 35/48, T 147456, FPS 96, 50-training-episode: mean/median -1.8/-1.4, min/max -7.2/7.8
Update 36/48, T 151552, FPS 96, 50-training-episode: mean/median 0.2/-1.5, min/max -7.4/98.8
Update 37/48, T 155648, FPS 96, 50-training-episode: mean/median -1.6/-1.4, min/max -8.0/7.5
Update 38/48, T 159744, FPS 95, 50-training-episode: mean/median 0.8/-1.3, min/max -4.8/108.8
Update 39/48, T 163840, FPS 96, 50-training-episode: mean/median -1.9/-1.4, min/max -6.3/-0.8
Update 40/48, T 167936, FPS 96, 50-training-episode: mean/median 6.2/-1.4, min/max -6.6/99.0
Update 41/48, T 172032, FPS 95, 50-training-episode: mean/median -1.7/-1.4, min/max -5.1/4.9
Update 42/48, T 176128, FPS 96, 50-training-episode: mean/median -2.4/-1.8, min/max -7.1/4.7
Update 43/48, T 180224, FPS 95, 50-training-episode: mean/median -1.7/-1.5, min/max -5.9/6.8
Update 44/48, T 184320, FPS 95, 50-training-episode: mean/median -2.3/-1.6, min/max -6.1/-0.8
Update 45/48, T 188416, FPS 95, 50-training-episode: mean/median 2.6/-1.4, min/max -4.9/108.6
Update 46/48, T 192512, FPS 95, 50-training-episode: mean/median -1.6/-1.4, min/max -8.2/6.8
Saved ./trained_models/ExptWalking20250730/plume_walk-v3_20250730_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.40.5_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed864272.pt
Update 47/48, T 196608, FPS 95, 50-training-episode: mean/median 0.0/-1.6, min/max -7.7/98.6
Saved ./trained_models/ExptWalking20250730//plume_walk-v3_20250730_VRNN_constantx5b5noisy3x5b5_stepoobmetabolicturnfound_bx34_t1000000200000_q0.40.5_dmx0.80.8_dmn0.70.4_h64_wd0.00012_n2_walking_seed864272.pt
Starting evaluation
Evaluating on dataset: switch15x5b5
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x17b692c70>, 't_val_min': 10.0, 'sim_steps_max': 2050, 'reset_offset_tmax': 30, 'dataset': 'switch15x5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 8642, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
switch15x5b5
Exception: [Errno 2] No such file or directory: '/Users/aaravsinha/plume/plumedata//puff_data_switch15x5b5.pickle'
Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 271, in eval_loop
    env = make_vec_envs(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 132, in make_vec_envs
    envs = DummyVecEnv(envs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 26, in __init__
    self.envs = [fn() for fn in env_fns]
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 26, in <listcomp>
    self.envs = [fn() for fn in env_fns]
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 34, in _thunk
    env = plume_env.PlumeEnvironment(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 116, in __init__
    self.set_dataset(dataset)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 205, in set_dataset
    self.data_puffs_all, self.data_wind_all = sim_analysis.load_plume(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 173, in load_plume
    data_puffs = pandas.read_pickle(puff_filename)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/pickle.py", line 185, in read_pickle
    with get_handle(
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/aaravsinha/plume/plumedata//puff_data_switch15x5b5.pickle'
Evaluating on dataset: switch30x5b5
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x17b692d00>, 't_val_min': 10.0, 'sim_steps_max': 2050, 'reset_offset_tmax': 30, 'dataset': 'switch30x5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 8642, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
switch30x5b5
Exception: [Errno 2] No such file or directory: '/Users/aaravsinha/plume/plumedata//puff_data_switch30x5b5.pickle'
Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 271, in eval_loop
    env = make_vec_envs(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 132, in make_vec_envs
    envs = DummyVecEnv(envs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 26, in __init__
    self.envs = [fn() for fn in env_fns]
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 26, in <listcomp>
    self.envs = [fn() for fn in env_fns]
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 34, in _thunk
    env = plume_env.PlumeEnvironment(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 116, in __init__
    self.set_dataset(dataset)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 205, in set_dataset
    self.data_puffs_all, self.data_wind_all = sim_analysis.load_plume(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 173, in load_plume
    data_puffs = pandas.read_pickle(puff_filename)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/pickle.py", line 185, in read_pickle
    with get_handle(
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/aaravsinha/plume/plumedata//puff_data_switch30x5b5.pickle'
Evaluating on dataset: switch45x5b5
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x17b692b50>, 't_val_min': 10.0, 'sim_steps_max': 2050, 'reset_offset_tmax': 30, 'dataset': 'switch45x5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 8642, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
switch45x5b5
Exception: [Errno 2] No such file or directory: '/Users/aaravsinha/plume/plumedata//puff_data_switch45x5b5.pickle'
Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 271, in eval_loop
    env = make_vec_envs(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 132, in make_vec_envs
    envs = DummyVecEnv(envs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 26, in __init__
    self.envs = [fn() for fn in env_fns]
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 26, in <listcomp>
    self.envs = [fn() for fn in env_fns]
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 34, in _thunk
    env = plume_env.PlumeEnvironment(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 116, in __init__
    self.set_dataset(dataset)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 205, in set_dataset
    self.data_puffs_all, self.data_wind_all = sim_analysis.load_plume(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 173, in load_plume
    data_puffs = pandas.read_pickle(puff_filename)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/pickle.py", line 185, in read_pickle
    with get_handle(
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/aaravsinha/plume/plumedata//puff_data_switch45x5b5.pickle'
Evaluating on dataset: constantx5b5
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x17b692f40>, 't_val_min': 10.0, 'sim_steps_max': 2050, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 8642, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
Using fixed evaluation sequence [time, angle, loc_y]... (240 episodes) 
Episode: 0, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 1, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 2, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 3, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 4, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 5, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 6, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 7, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 8, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 9, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 10, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 11, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 12, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 13, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 14, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 15, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 16, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 17, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 18, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 19, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 20, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 21, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 22, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 23, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 24, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 25, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 26, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 27, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 28, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 29, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 30, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 31, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 32, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 33, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 34, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 35, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 36, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 37, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 38, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 39, reward_sum: -10.0, Steps: 1, Reason: OOB
Exception: name 'nan' is not defined
Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 231, in resolve
    return self.resolvers[key]
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'nan'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 242, in resolve
    return self.temps[key]
KeyError: 'nan'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 289, in eval_loop
    episode_logs, episode_summaries = evaluate_agent(actor_critic, env, args)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 180, in evaluate_agent
    obs = env.reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 208, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/vec_normalize.py", line 284, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 74, in reset
    obs = self.envs[env_idx].reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 448, in reset
    observation = self.sense_environment()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 269, in sense_environment
    odor_observation = sim_analysis.get_concentration_at_tidx(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 263, in get_concentration_at_tidx
    d = data[data.tidx==tidx].query(q)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4828, in query
    res = self.eval(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4954, in eval
    return _eval(expr, inplace=inplace, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/eval.py", line 339, in eval
    parsed_expr = Expr(expr, engine=engine, parser=parser, env=env)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 809, in __init__
    self.terms = self.parse()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 828, in parse
    return self._visitor.visit(self.expr)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 419, in visit_Module
    return self.visit(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 422, in visit_Expr
    return self.visit(node.value, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 746, in visit_BoolOp
    return reduce(visitor, operands)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 740, in visitor
    rhs = self._try_visit_binop(y)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 735, in _try_visit_binop
    return self.visit(bop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 719, in visit_Compare
    return self.visit(binop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 535, in visit_BinOp
    op, op_class, left, right = self._maybe_transform_eq_ne(node)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 453, in _maybe_transform_eq_ne
    left = self.visit(node.left, side="left")
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 545, in visit_Name
    return self.term_type(node.id, self.env, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 91, in __init__
    self._value = self._resolve_name()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 115, in _resolve_name
    res = self.env.resolve(local_name, is_local=is_local)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 244, in resolve
    raise UndefinedVariableError(key, is_local) from err
pandas.errors.UndefinedVariableError: name 'nan' is not defined
Sparse/birthx: 0.8
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x17b6a1190>, 't_val_min': 10.0, 'sim_steps_max': 2050, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 0.8, 'env_dt': 0.04, 'loc_algo': 'quantile', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 8642, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
Sparsifying puffs to 0.8x
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
Using fixed evaluation sequence [time, angle, loc_y]... (240 episodes) 
Episode: 0, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 1, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 2, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 3, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 4, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 5, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 6, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 7, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 8, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 9, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 10, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 11, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 12, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 13, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 14, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 15, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 16, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 17, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 18, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 19, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 20, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 21, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 22, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 23, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 24, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 25, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 26, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 27, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 28, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 29, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 30, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 31, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 32, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 33, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 34, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 35, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 36, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 37, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 38, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 39, reward_sum: -10.0, Steps: 1, Reason: OOB
Exception: name 'nan' is not defined
Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 231, in resolve
    return self.resolvers[key]
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'nan'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 242, in resolve
    return self.temps[key]
KeyError: 'nan'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 363, in eval_loop
    episode_logs, episode_summaries = evaluate_agent(actor_critic, env, args)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 180, in evaluate_agent
    obs = env.reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 208, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/vec_normalize.py", line 284, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 74, in reset
    obs = self.envs[env_idx].reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 448, in reset
    observation = self.sense_environment()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 269, in sense_environment
    odor_observation = sim_analysis.get_concentration_at_tidx(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 263, in get_concentration_at_tidx
    d = data[data.tidx==tidx].query(q)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4828, in query
    res = self.eval(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4954, in eval
    return _eval(expr, inplace=inplace, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/eval.py", line 339, in eval
    parsed_expr = Expr(expr, engine=engine, parser=parser, env=env)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 809, in __init__
    self.terms = self.parse()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 828, in parse
    return self._visitor.visit(self.expr)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 419, in visit_Module
    return self.visit(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 422, in visit_Expr
    return self.visit(node.value, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 746, in visit_BoolOp
    return reduce(visitor, operands)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 740, in visitor
    rhs = self._try_visit_binop(y)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 735, in _try_visit_binop
    return self.visit(bop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 719, in visit_Compare
    return self.visit(binop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 535, in visit_BinOp
    op, op_class, left, right = self._maybe_transform_eq_ne(node)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 453, in _maybe_transform_eq_ne
    left = self.visit(node.left, side="left")
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 545, in visit_Name
    return self.term_type(node.id, self.env, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 91, in __init__
    self._value = self._resolve_name()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 115, in _resolve_name
    res = self.env.resolve(local_name, is_local=is_local)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 244, in resolve
    raise UndefinedVariableError(key, is_local) from err
pandas.errors.UndefinedVariableError: name 'nan' is not defined
Sparse/birthx: 0.6
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x16efba400>, 't_val_min': 10.0, 'sim_steps_max': 2050, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 0.6, 'env_dt': 0.04, 'loc_algo': 'quantile', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 8642, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
Sparsifying puffs to 0.6x
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
Using fixed evaluation sequence [time, angle, loc_y]... (240 episodes) 
Episode: 0, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 1, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 2, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 3, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 4, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 5, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 6, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 7, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 8, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 9, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 10, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 11, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 12, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 13, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 14, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 15, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 16, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 17, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 18, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 19, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 20, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 21, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 22, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 23, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 24, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 25, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 26, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 27, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 28, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 29, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 30, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 31, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 32, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 33, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 34, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 35, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 36, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 37, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 38, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 39, reward_sum: -10.0, Steps: 1, Reason: OOB
Exception: name 'nan' is not defined
Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 231, in resolve
    return self.resolvers[key]
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'nan'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 242, in resolve
    return self.temps[key]
KeyError: 'nan'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 363, in eval_loop
    episode_logs, episode_summaries = evaluate_agent(actor_critic, env, args)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 180, in evaluate_agent
    obs = env.reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 208, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/vec_normalize.py", line 284, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 74, in reset
    obs = self.envs[env_idx].reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 448, in reset
    observation = self.sense_environment()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 269, in sense_environment
    odor_observation = sim_analysis.get_concentration_at_tidx(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 263, in get_concentration_at_tidx
    d = data[data.tidx==tidx].query(q)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4828, in query
    res = self.eval(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4954, in eval
    return _eval(expr, inplace=inplace, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/eval.py", line 339, in eval
    parsed_expr = Expr(expr, engine=engine, parser=parser, env=env)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 809, in __init__
    self.terms = self.parse()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 828, in parse
    return self._visitor.visit(self.expr)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 419, in visit_Module
    return self.visit(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 422, in visit_Expr
    return self.visit(node.value, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 746, in visit_BoolOp
    return reduce(visitor, operands)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 740, in visitor
    rhs = self._try_visit_binop(y)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 735, in _try_visit_binop
    return self.visit(bop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 719, in visit_Compare
    return self.visit(binop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 535, in visit_BinOp
    op, op_class, left, right = self._maybe_transform_eq_ne(node)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 453, in _maybe_transform_eq_ne
    left = self.visit(node.left, side="left")
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 545, in visit_Name
    return self.term_type(node.id, self.env, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 91, in __init__
    self._value = self._resolve_name()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 115, in _resolve_name
    res = self.env.resolve(local_name, is_local=is_local)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 244, in resolve
    raise UndefinedVariableError(key, is_local) from err
pandas.errors.UndefinedVariableError: name 'nan' is not defined
Sparse/birthx: 0.4
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x162a97790>, 't_val_min': 10.0, 'sim_steps_max': 2050, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 0.4, 'env_dt': 0.04, 'loc_algo': 'quantile', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 8642, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
Sparsifying puffs to 0.4x
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
Using fixed evaluation sequence [time, angle, loc_y]... (240 episodes) 
Episode: 0, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 1, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 2, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 3, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 4, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 5, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 6, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 7, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 8, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 9, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 10, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 11, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 12, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 13, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 14, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 15, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 16, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 17, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 18, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 19, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 20, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 21, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 22, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 23, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 24, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 25, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 26, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 27, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 28, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 29, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 30, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 31, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 32, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 33, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 34, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 35, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 36, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 37, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 38, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 39, reward_sum: -10.0, Steps: 1, Reason: OOB
Exception: name 'nan' is not defined
Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 231, in resolve
    return self.resolvers[key]
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'nan'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 242, in resolve
    return self.temps[key]
KeyError: 'nan'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 363, in eval_loop
    episode_logs, episode_summaries = evaluate_agent(actor_critic, env, args)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 180, in evaluate_agent
    obs = env.reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 208, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/vec_normalize.py", line 284, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 74, in reset
    obs = self.envs[env_idx].reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 448, in reset
    observation = self.sense_environment()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 269, in sense_environment
    odor_observation = sim_analysis.get_concentration_at_tidx(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 263, in get_concentration_at_tidx
    d = data[data.tidx==tidx].query(q)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4828, in query
    res = self.eval(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4954, in eval
    return _eval(expr, inplace=inplace, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/eval.py", line 339, in eval
    parsed_expr = Expr(expr, engine=engine, parser=parser, env=env)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 809, in __init__
    self.terms = self.parse()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 828, in parse
    return self._visitor.visit(self.expr)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 419, in visit_Module
    return self.visit(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 422, in visit_Expr
    return self.visit(node.value, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 746, in visit_BoolOp
    return reduce(visitor, operands)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 740, in visitor
    rhs = self._try_visit_binop(y)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 735, in _try_visit_binop
    return self.visit(bop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 719, in visit_Compare
    return self.visit(binop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 535, in visit_BinOp
    op, op_class, left, right = self._maybe_transform_eq_ne(node)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 453, in _maybe_transform_eq_ne
    left = self.visit(node.left, side="left")
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 545, in visit_Name
    return self.term_type(node.id, self.env, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 91, in __init__
    self._value = self._resolve_name()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 115, in _resolve_name
    res = self.env.resolve(local_name, is_local=is_local)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 244, in resolve
    raise UndefinedVariableError(key, is_local) from err
pandas.errors.UndefinedVariableError: name 'nan' is not defined
Sparse/birthx: 0.2
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x16f46d460>, 't_val_min': 10.0, 'sim_steps_max': 2050, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 0.2, 'env_dt': 0.04, 'loc_algo': 'quantile', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 8642, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
Sparsifying puffs to 0.2x
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
Using fixed evaluation sequence [time, angle, loc_y]... (240 episodes) 
Episode: 0, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 1, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 2, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 3, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 4, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 5, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 6, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 7, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 8, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 9, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 10, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 11, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 12, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 13, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 14, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 15, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 16, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 17, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 18, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 19, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 20, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 21, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 22, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 23, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 24, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 25, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 26, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 27, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 28, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 29, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 30, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 31, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 32, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 33, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 34, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 35, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 36, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 37, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 38, reward_sum: -10.0, Steps: 1, Reason: OOB
Episode: 39, reward_sum: -10.0, Steps: 1, Reason: OOB
Exception: name 'nan' is not defined
Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 231, in resolve
    return self.resolvers[key]
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'nan'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 242, in resolve
    return self.temps[key]
KeyError: 'nan'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 363, in eval_loop
    episode_logs, episode_summaries = evaluate_agent(actor_critic, env, args)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 180, in evaluate_agent
    obs = env.reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 208, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/vec_normalize.py", line 284, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 74, in reset
    obs = self.envs[env_idx].reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 448, in reset
    observation = self.sense_environment()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 269, in sense_environment
    odor_observation = sim_analysis.get_concentration_at_tidx(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 263, in get_concentration_at_tidx
    d = data[data.tidx==tidx].query(q)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4828, in query
    res = self.eval(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4954, in eval
    return _eval(expr, inplace=inplace, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/eval.py", line 339, in eval
    parsed_expr = Expr(expr, engine=engine, parser=parser, env=env)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 809, in __init__
    self.terms = self.parse()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 828, in parse
    return self._visitor.visit(self.expr)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 419, in visit_Module
    return self.visit(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 422, in visit_Expr
    return self.visit(node.value, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 746, in visit_BoolOp
    return reduce(visitor, operands)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 740, in visitor
    rhs = self._try_visit_binop(y)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 735, in _try_visit_binop
    return self.visit(bop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 719, in visit_Compare
    return self.visit(binop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 535, in visit_BinOp
    op, op_class, left, right = self._maybe_transform_eq_ne(node)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 453, in _maybe_transform_eq_ne
    left = self.visit(node.left, side="left")
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 545, in visit_Name
    return self.term_type(node.id, self.env, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 91, in __init__
    self._value = self._resolve_name()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 115, in _resolve_name
    res = self.env.resolve(local_name, is_local=is_local)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 244, in resolve
    raise UndefinedVariableError(key, is_local) from err
pandas.errors.UndefinedVariableError: name 'nan' is not defined
Evaluating on dataset: noisy3x5b5
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x17b692fd0>, 't_val_min': 10.0, 'sim_steps_max': 2050, 'reset_offset_tmax': 30, 'dataset': 'noisy3x5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 0.2, 'env_dt': 0.04, 'loc_algo': 'quantile', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 8642, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
noisy3x5b5
Sparsifying puffs to 0.2x
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
Using fixed evaluation sequence [time, angle, loc_y]... (240 episodes) 
Exception: name 'nan' is not defined
Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 231, in resolve
    return self.resolvers[key]
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/opt/anaconda3/envs/py39/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'nan'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 242, in resolve
    return self.temps[key]
KeyError: 'nan'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 289, in eval_loop
    episode_logs, episode_summaries = evaluate_agent(actor_critic, env, args)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 180, in evaluate_agent
    obs = env.reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 208, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/vec_normalize.py", line 284, in reset
    obs = self.venv.reset()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 74, in reset
    obs = self.envs[env_idx].reset()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 448, in reset
    observation = self.sense_environment()
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 269, in sense_environment
    odor_observation = sim_analysis.get_concentration_at_tidx(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 263, in get_concentration_at_tidx
    d = data[data.tidx==tidx].query(q)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4828, in query
    res = self.eval(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py", line 4954, in eval
    return _eval(expr, inplace=inplace, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/eval.py", line 339, in eval
    parsed_expr = Expr(expr, engine=engine, parser=parser, env=env)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 809, in __init__
    self.terms = self.parse()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 828, in parse
    return self._visitor.visit(self.expr)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 419, in visit_Module
    return self.visit(expr, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 422, in visit_Expr
    return self.visit(node.value, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 746, in visit_BoolOp
    return reduce(visitor, operands)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 740, in visitor
    rhs = self._try_visit_binop(y)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 735, in _try_visit_binop
    return self.visit(bop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 719, in visit_Compare
    return self.visit(binop)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 535, in visit_BinOp
    op, op_class, left, right = self._maybe_transform_eq_ne(node)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 453, in _maybe_transform_eq_ne
    left = self.visit(node.left, side="left")
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 413, in visit
    return visitor(node, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/expr.py", line 545, in visit_Name
    return self.term_type(node.id, self.env, **kwargs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 91, in __init__
    self._value = self._resolve_name()
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/ops.py", line 115, in _resolve_name
    res = self.env.resolve(local_name, is_local=is_local)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/computation/scope.py", line 244, in resolve
    raise UndefinedVariableError(key, is_local) from err
pandas.errors.UndefinedVariableError: name 'nan' is not defined
Evaluating on dataset: noisy6x5b5
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x17e4f50d0>, 't_val_min': 10.0, 'sim_steps_max': 2050, 'reset_offset_tmax': 30, 'dataset': 'noisy6x5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1, 'turnx': 1.0, 'birthx': 1.0, 'birthx_max': 0.2, 'env_dt': 0.04, 'loc_algo': 'quantile', 'qvar': 0.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': False, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 8642, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
noisy6x5b5
Exception: [Errno 2] No such file or directory: '/Users/aaravsinha/plume/plumedata//puff_data_noisy6x5b5.pickle'
Traceback (most recent call last):
  File "/Users/aaravsinha/manyplume/oneplume/ppo/evalCli.py", line 271, in eval_loop
    env = make_vec_envs(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 132, in make_vec_envs
    envs = DummyVecEnv(envs)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 26, in __init__
    self.envs = [fn() for fn in env_fns]
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 26, in <listcomp>
    self.envs = [fn() for fn in env_fns]
  File "/Users/aaravsinha/manyplume/oneplume/ppo/a2c_ppo_acktr/envs.py", line 34, in _thunk
    env = plume_env.PlumeEnvironment(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 116, in __init__
    self.set_dataset(dataset)
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../plume_env.py", line 205, in set_dataset
    self.data_puffs_all, self.data_wind_all = sim_analysis.load_plume(
  File "/Users/aaravsinha/manyplume/oneplume/ppo/../sim_analysis.py", line 173, in load_plume
    data_puffs = pandas.read_pickle(puff_filename)
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/pickle.py", line 185, in read_pickle
    with get_handle(
  File "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/aaravsinha/plume/plumedata//puff_data_noisy6x5b5.pickle'
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x1011fb220>, 't_val_min': 10.0, 'sim_steps_max': 2050, 'reset_offset_tmax': 30, 'dataset': 'noisy3x5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 4.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.5, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': True, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 8642, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
noisy3x5b5
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x1011fb220>, 't_val_min': 10.0, 'sim_steps_max': 2050, 'reset_offset_tmax': 30, 'dataset': 'noisy3x5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 4.0, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 0.5, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.4, 'r_shaping': ['step', 'oob', 'metabolic', 'turn', 'found'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.14159, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': True, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 8642, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
noisy3x5b5
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob', 'metabolic', 'turn', 'found']
