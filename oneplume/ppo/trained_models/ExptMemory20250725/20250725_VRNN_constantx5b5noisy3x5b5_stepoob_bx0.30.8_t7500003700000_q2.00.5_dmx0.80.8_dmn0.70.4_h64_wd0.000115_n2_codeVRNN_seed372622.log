CUDA: False
Namespace(algo='ppo', lr=0.0003, eps=1e-05, alpha=0.99, gamma=0.99, use_gae=True, gae_lambda=0.95, entropy_coef=0.005, value_loss_coef=0.5, max_grad_norm=0.5, seed=3726, cuda_deterministic=False, num_processes=2, num_steps=2048, ppo_epoch=10, num_mini_batch=2, clip_param=0.2, log_interval=1, save_interval=100, no_cuda=False, use_proper_time_limits=False, recurrent_policy=True, use_linear_lr_decay=True, env_name='plume', log_dir='/tmp/gym/', save_dir='./trained_models/ExptMemory20250725/', dynamic=False, eval_type='fixed', eval_episodes=20, eval_interval=None, weight_decay=0.000115, rnn_type='VRNN', hidden_size=64, betadist=False, stacking=0, masking=None, stride=1, dataset=['constantx5b5', 'noisy3x5b5'], num_env_steps=[750000, 3700000], qvar=[2.0, 0.5], birthx=[0.3, 0.8], diff_max=[0.8, 0.8], diff_min=[0.7, 0.4], birthx_max=1.0, dryrun=False, curriculum=False, turnx=1.0, movex=1.0, auto_movex=False, auto_reward=False, loc_algo='uniform', time_algo='uniform', env_dt=0.04, outsuffix='20250725_VRNN_constantx5b5noisy3x5b5_stepoob_bx0.30.8_t7500003700000_q2.00.5_dmx0.80.8_dmn0.70.4_h64_wd0.000115_n2_codeVRNN_seed372622', walking=True, radiusx=1.0, diffusion_min=1.0, diffusion_max=1.0, r_shaping=['step', 'oob'], wind_rel=True, action_feedback=False, squash_action=True, flipping=True, odor_scaling=True, stray_max=2.0, test_episodes=50, viz_episodes=10, model_fname='', obs_noise=0.0, act_noise=0.0, cuda=False)
PPO Args ---> Namespace(algo='ppo', lr=0.0003, eps=1e-05, alpha=0.99, gamma=0.99, use_gae=True, gae_lambda=0.95, entropy_coef=0.005, value_loss_coef=0.5, max_grad_norm=0.5, seed=3726, cuda_deterministic=False, num_processes=2, num_steps=2048, ppo_epoch=10, num_mini_batch=2, clip_param=0.2, log_interval=1, save_interval=100, no_cuda=False, use_proper_time_limits=False, recurrent_policy=True, use_linear_lr_decay=True, env_name='plume', log_dir='/tmp/gym/', save_dir='./trained_models/ExptMemory20250725/', dynamic=False, eval_type='fixed', eval_episodes=20, eval_interval=None, weight_decay=0.000115, rnn_type='VRNN', hidden_size=64, betadist=False, stacking=0, masking=None, stride=1, dataset=['constantx5b5', 'noisy3x5b5'], num_env_steps=[750000, 3700000], qvar=[2.0, 0.5], birthx=[0.3, 0.8], diff_max=[0.8, 0.8], diff_min=[0.7, 0.4], birthx_max=1.0, dryrun=False, curriculum=False, turnx=1.0, movex=1.0, auto_movex=False, auto_reward=False, loc_algo='uniform', time_algo='uniform', env_dt=0.04, outsuffix='20250725_VRNN_constantx5b5noisy3x5b5_stepoob_bx0.30.8_t7500003700000_q2.00.5_dmx0.80.8_dmn0.70.4_h64_wd0.000115_n2_codeVRNN_seed372622', walking=True, radiusx=1.0, diffusion_min=1.0, diffusion_max=1.0, r_shaping=['step', 'oob'], wind_rel=True, action_feedback=False, squash_action=True, flipping=True, odor_scaling=True, stray_max=2.0, test_episodes=50, viz_episodes=10, model_fname='', obs_noise=0.0, act_noise=0.0, cuda=False)
Using Precomputed Plume...
Using Precomputed Plume...
2025-07-25 09:14:21.437 python[41731:41425203] +[NSXPCSharedListener endpointForReply:withListenerName:replyErrorCode:]: an error occurred while attempting to obtain endpoint for listener 'ClientCallsAuxiliary': Connection invalid
2025-07-25 09:14:21.437 python[41729:41425201] +[NSXPCSharedListener endpointForReply:withListenerName:replyErrorCode:]: an error occurred while attempting to obtain endpoint for listener 'ClientCallsAuxiliary': Connection invalid
Using Precomputed Plume...
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x31464ad30>, 't_val_min': 60.0, 'sim_steps_max': 300, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 0.3, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 2.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.7, 'r_shaping': ['step', 'oob'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.141592653589793, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': True, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 3726, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob']
Using MLPBase
hidden_size 64
Using VanillaRNN
Saved ./trained_models/ExptMemory20250725//plume_20250725_VRNN_constantx5b5noisy3x5b5_stepoob_bx0.30.8_t7500003700000_q2.00.5_dmx0.80.8_dmn0.70.4_h64_wd0.000115_n2_codeVRNN_seed372622.pt.start
Stage: 0/2 - constantx5b5 b0.3 q2.0 n750000
Saved ./trained_models/ExptMemory20250725/plume_20250725_VRNN_constantx5b5noisy3x5b5_stepoob_bx0.30.8_t7500003700000_q2.00.5_dmx0.80.8_dmn0.70.4_h64_wd0.000115_n2_codeVRNN_seed372622.pt
Update 0/183, T 4096, FPS 394, 50-training-episode: mean/median -8.9/-8.5, min/max -25.3/-0.9
Update 1/183, T 8192, FPS 387, 50-training-episode: mean/median -8.2/-7.8, min/max -21.2/-0.8
Update 2/183, T 12288, FPS 399, 50-training-episode: mean/median -9.7/-9.4, min/max -23.7/-0.9
Update 3/183, T 16384, FPS 403, 50-training-episode: mean/median -9.3/-7.6, min/max -27.3/-1.4
Update 4/183, T 20480, FPS 401, 50-training-episode: mean/median -9.6/-9.1, min/max -23.9/-1.5
Update 5/183, T 24576, FPS 398, 50-training-episode: mean/median -7.7/-6.1, min/max -22.9/-1.6
Update 6/183, T 28672, FPS 400, 50-training-episode: mean/median -8.7/-7.2, min/max -26.6/-1.3
Update 7/183, T 32768, FPS 397, 50-training-episode: mean/median -8.6/-6.8, min/max -20.2/-1.3
Update 8/183, T 36864, FPS 398, 50-training-episode: mean/median -9.0/-8.5, min/max -25.7/-0.9
Update 9/183, T 40960, FPS 398, 50-training-episode: mean/median -9.0/-8.8, min/max -20.8/-0.9
Update 10/183, T 45056, FPS 399, 50-training-episode: mean/median -9.9/-11.4, min/max -19.4/-1.5
Update 11/183, T 49152, FPS 399, 50-training-episode: mean/median -8.4/-7.8, min/max -19.5/-1.0
Update 12/183, T 53248, FPS 398, 50-training-episode: mean/median -8.2/-8.9, min/max -22.1/-1.8
Update 13/183, T 57344, FPS 401, 50-training-episode: mean/median -8.7/-8.5, min/max -21.2/-0.9
Update 14/183, T 61440, FPS 404, 50-training-episode: mean/median -7.7/-6.7, min/max -22.8/-0.9
Update 15/183, T 65536, FPS 406, 50-training-episode: mean/median -9.2/-8.8, min/max -24.6/-1.6
Update 16/183, T 69632, FPS 407, 50-training-episode: mean/median -8.6/-9.0, min/max -24.3/-0.9
Update 17/183, T 73728, FPS 409, 50-training-episode: mean/median -8.3/-8.0, min/max -23.8/-1.0
Update 18/183, T 77824, FPS 410, 50-training-episode: mean/median -8.4/-8.0, min/max -17.9/-0.8
Update 19/183, T 81920, FPS 411, 50-training-episode: mean/median -7.4/-7.4, min/max -15.3/-1.2
Update 20/183, T 86016, FPS 412, 50-training-episode: mean/median -7.2/-6.9, min/max -19.5/-1.3
Update 21/183, T 90112, FPS 413, 50-training-episode: mean/median -9.0/-8.8, min/max -22.2/-0.8
Update 22/183, T 94208, FPS 414, 50-training-episode: mean/median -8.7/-8.8, min/max -23.2/-1.0
Update 23/183, T 98304, FPS 415, 50-training-episode: mean/median -8.4/-7.9, min/max -18.2/-0.9
Update 24/183, T 102400, FPS 416, 50-training-episode: mean/median -8.3/-7.4, min/max -20.6/-1.1
Update 25/183, T 106496, FPS 416, 50-training-episode: mean/median -8.3/-7.1, min/max -18.6/-1.4
Update 26/183, T 110592, FPS 417, 50-training-episode: mean/median -8.0/-8.4, min/max -19.5/-0.8
Update 27/183, T 114688, FPS 418, 50-training-episode: mean/median -7.9/-7.7, min/max -22.1/-0.9
Update 28/183, T 118784, FPS 419, 50-training-episode: mean/median -8.0/-7.3, min/max -22.9/-0.9
Update 29/183, T 122880, FPS 419, 50-training-episode: mean/median -8.5/-8.6, min/max -19.0/-1.5
Update 30/183, T 126976, FPS 419, 50-training-episode: mean/median -7.9/-7.8, min/max -20.3/-1.3
Update 31/183, T 131072, FPS 420, 50-training-episode: mean/median -7.4/-6.8, min/max -16.6/-0.9
Update 32/183, T 135168, FPS 420, 50-training-episode: mean/median -8.7/-8.1, min/max -25.0/-1.1
Update 33/183, T 139264, FPS 421, 50-training-episode: mean/median -7.2/-7.0, min/max -16.5/-0.9
Update 34/183, T 143360, FPS 421, 50-training-episode: mean/median -6.7/-6.4, min/max -15.0/-1.4
Update 35/183, T 147456, FPS 422, 50-training-episode: mean/median -7.9/-7.9, min/max -16.2/-0.8
Update 36/183, T 151552, FPS 422, 50-training-episode: mean/median -8.6/-7.5, min/max -27.0/-1.3
Update 37/183, T 155648, FPS 423, 50-training-episode: mean/median -8.2/-8.2, min/max -18.4/-1.2
Update 38/183, T 159744, FPS 423, 50-training-episode: mean/median -7.8/-7.4, min/max -20.8/-1.4
Update 39/183, T 163840, FPS 423, 50-training-episode: mean/median -7.2/-8.0, min/max -16.3/-1.5
Update 40/183, T 167936, FPS 424, 50-training-episode: mean/median -6.6/-6.9, min/max -12.6/-1.4
Update 41/183, T 172032, FPS 424, 50-training-episode: mean/median -8.7/-8.9, min/max -19.0/-1.6
Update 42/183, T 176128, FPS 423, 50-training-episode: mean/median -7.5/-6.8, min/max -20.9/-0.9
Update 43/183, T 180224, FPS 424, 50-training-episode: mean/median -8.3/-8.0, min/max -20.0/-1.2
Update 44/183, T 184320, FPS 424, 50-training-episode: mean/median -8.3/-7.2, min/max -18.8/-2.3
Update 45/183, T 188416, FPS 424, 50-training-episode: mean/median -7.7/-8.4, min/max -19.0/-1.0
Update 46/183, T 192512, FPS 425, 50-training-episode: mean/median -9.1/-9.6, min/max -16.4/-1.0
Update 47/183, T 196608, FPS 425, 50-training-episode: mean/median -7.2/-6.7, min/max -13.6/-1.0
Update 48/183, T 200704, FPS 424, 50-training-episode: mean/median -7.6/-6.6, min/max -18.8/-0.9
Update 49/183, T 204800, FPS 424, 50-training-episode: mean/median -7.9/-7.6, min/max -19.8/-1.1
Update 50/183, T 208896, FPS 424, 50-training-episode: mean/median -7.2/-6.4, min/max -16.3/-1.1
Update 51/183, T 212992, FPS 424, 50-training-episode: mean/median -7.8/-7.6, min/max -14.1/-1.4
Update 52/183, T 217088, FPS 424, 50-training-episode: mean/median -7.0/-5.7, min/max -17.1/-1.1
Update 53/183, T 221184, FPS 424, 50-training-episode: mean/median -7.2/-7.0, min/max -19.5/-1.1
Update 54/183, T 225280, FPS 424, 50-training-episode: mean/median -8.1/-8.3, min/max -15.7/-1.0
Update 55/183, T 229376, FPS 424, 50-training-episode: mean/median -7.3/-7.0, min/max -22.5/-1.3
Update 56/183, T 233472, FPS 424, 50-training-episode: mean/median -7.9/-7.0, min/max -17.8/-1.1
Update 57/183, T 237568, FPS 424, 50-training-episode: mean/median -7.8/-7.9, min/max -22.1/-0.9
Update 58/183, T 241664, FPS 424, 50-training-episode: mean/median -8.0/-8.8, min/max -16.7/-0.9
Update 59/183, T 245760, FPS 424, 50-training-episode: mean/median -6.9/-6.6, min/max -23.1/-1.1
Update 60/183, T 249856, FPS 424, 50-training-episode: mean/median -8.1/-7.9, min/max -15.9/-0.9
Update 61/183, T 253952, FPS 423, 50-training-episode: mean/median -7.2/-7.7, min/max -15.6/-1.0
Update 62/183, T 258048, FPS 424, 50-training-episode: mean/median -7.0/-6.4, min/max -17.1/-1.1
Update 63/183, T 262144, FPS 424, 50-training-episode: mean/median -6.5/-6.4, min/max -15.8/-1.0
Update 64/183, T 266240, FPS 424, 50-training-episode: mean/median -8.3/-8.0, min/max -22.5/-1.6
Update 65/183, T 270336, FPS 424, 50-training-episode: mean/median -7.1/-6.8, min/max -19.2/-1.2
Update 66/183, T 274432, FPS 424, 50-training-episode: mean/median -7.9/-7.4, min/max -24.7/-1.6
Update 67/183, T 278528, FPS 424, 50-training-episode: mean/median -7.5/-7.9, min/max -17.6/-1.3
Update 68/183, T 282624, FPS 424, 50-training-episode: mean/median -7.0/-6.2, min/max -16.5/-1.0
Update 69/183, T 286720, FPS 424, 50-training-episode: mean/median -7.6/-7.0, min/max -18.4/-1.1
Update 70/183, T 290816, FPS 424, 50-training-episode: mean/median -7.1/-7.9, min/max -13.2/-1.0
Update 71/183, T 294912, FPS 424, 50-training-episode: mean/median -7.2/-6.6, min/max -16.0/-1.4
Update 72/183, T 299008, FPS 424, 50-training-episode: mean/median -7.1/-7.8, min/max -14.3/-1.3
Update 73/183, T 303104, FPS 424, 50-training-episode: mean/median -7.0/-7.2, min/max -14.5/-1.3
Update 74/183, T 307200, FPS 424, 50-training-episode: mean/median -6.7/-6.5, min/max -15.4/-1.1
Update 75/183, T 311296, FPS 423, 50-training-episode: mean/median -6.2/-5.9, min/max -15.0/-1.2
Update 76/183, T 315392, FPS 423, 50-training-episode: mean/median -8.3/-8.9, min/max -18.2/-1.7
Update 77/183, T 319488, FPS 422, 50-training-episode: mean/median -7.1/-7.0, min/max -15.8/-1.5
Update 78/183, T 323584, FPS 422, 50-training-episode: mean/median -7.0/-6.8, min/max -15.9/-1.0
Update 79/183, T 327680, FPS 420, 50-training-episode: mean/median -7.4/-6.8, min/max -16.3/-1.5
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x102ab3250>, 't_val_min': 60.0, 'sim_steps_max': 300, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 0.3, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 2.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.7, 'r_shaping': ['step', 'oob'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.141592653589793, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': True, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 3726, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob']
PlumeEnvironment: {'self': <plume_env.PlumeEnvironment object at 0x102ab3250>, 't_val_min': 60.0, 'sim_steps_max': 300, 'reset_offset_tmax': 30, 'dataset': 'constantx5b5', 'move_capacity': 2.0, 'turn_capacity': 19.634954084936208, 'wind_obsx': 1.0, 'movex': 1.0, 'turnx': 1.0, 'birthx': 0.3, 'birthx_max': 1.0, 'env_dt': 0.04, 'loc_algo': 'uniform', 'qvar': 2.0, 'time_algo': 'uniform', 'angle_algo': 'uniform', 'homed_radius': 0.2, 'stray_max': 2.0, 'wind_rel': True, 'auto_movex': False, 'auto_reward': False, 'diff_max': 0.8, 'diff_min': 0.7, 'r_shaping': ['step', 'oob'], 'rewardx': 1.0, 'rescale': False, 'squash_action': True, 'walking': True, 'walk_move': 0.05, 'walk_turn': 3.141592653589793, 'radiusx': 1.0, 'diffusion_min': 1.0, 'diffusion_max': 1.0, 'action_feedback': False, 'flipping': True, 'odor_scaling': True, 'obs_noise': 0.0, 'act_noise': 0.0, 'dynamic': False, 'seed': 3726, 'verbose': 0, '__class__': <class 'plume_env.PlumeEnvironment'>}
Squashing actions to 0-1
constantx5b5
wind: t_val_diff 0.03999999999999915 env_dt 0.04
puffs: t_val_diff 0.03999999999999915 env_dt 0.04
Reward Shaping ['step', 'oob']
